{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Sets\n",
    "\n",
    "## This is a rough work in progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Parameters\n",
    "\n",
    "Many different kinds of things are called \"parameters.\" Here are several categories.\n",
    "\n",
    "### Population parameters\n",
    "\n",
    "Any property of a population may be called a _parameter_.\n",
    "Examples include the population mean, percentiles, number of modes, etc.\n",
    "\n",
    "If the population has more than one \"value\" per item, e.g., if the population is a group of people each of whom has a height and a weight, then the population correlation between height and weight is a parameter.\n",
    "\n",
    "Similarly, consider a group of individuals and the values of some quantity (the \"response\") for each of those individuals without and with some intervention (notionally, a \"treatment\").\n",
    "The difference between the average response without the intervention and the average response with the intervention is a parameter (the _average treatment effect_).\n",
    "\n",
    "If we are sampling at random from a population, the probability distribution of the sample\n",
    "depends on the values in the population, and thus, in general, on the \n",
    "values of population parameters.\n",
    "(It will also depend on the sampling design.)\n",
    "\n",
    "### Functional parameters of probability distributions\n",
    "\n",
    "Suppose $X \\sim \\mathbb{P}$, where $\\mathbb{P}$ is a probability distribution on some space $\\mathcal{X}$ of possible outcomes.\n",
    "We assume that $\\mathbb{P} \\in \\mathcal{P}$, some known set of possible distributions.\n",
    "\n",
    "A _functional parameter_ $\\theta(\\mathbb{P})$ is a function of $\\mathbb{P}$.\n",
    "For instance the (population) mean is a functional parameter:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta(\\mathbb{P}) = \\mathbb{E}X \\equiv \\int_\\mathcal{X} x d\\mathbb{P}(x).\n",
    "\\end{equation}\n",
    "\n",
    "So are other moments of the probability distribution:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta(\\mathbb{P}) = \\mathbb{E}X^n \\equiv \\int_\\mathcal{X} x^n d\\mathbb{P}(x), \\;\\; n=1, 2, \\ldots .\n",
    "\\end{equation*}\n",
    "\n",
    "Other properties of $\\mathbb{P}$, such as percentiles of a univariate\n",
    "distribution, are also functional parameters.\n",
    "For instance, if $X$ is a real-valued random variable,\n",
    "then the $\\alpha$ percentile of $\\mathbb{P}$,\n",
    "\\begin{equation}\n",
    "\\theta(\\mathbb{P}) = \\inf \\left \\{x: \\int_{-\\infty}^x d\\mathbb{P}(x) \\ge \\alpha \\right \\},\n",
    "\\end{equation}\n",
    "is a functional parameter.\n",
    "\n",
    "For multivariate distributions, correlations among the components of $X$\n",
    "are functional parameters.\n",
    "\n",
    "In general, there can be distinct distributions $\\mathbb{P}$ and $\\mathbb{Q}$ such that \n",
    "$\\mathbb{P} \\ne \\mathbb{Q}$ but $\\theta(\\mathbb{P}) = \\theta(\\mathbb{Q})$. \n",
    "For instance there are infinitely many normal distributions with the\n",
    "same mean (but different variances).\n",
    "\n",
    "### Parameters as indices for sets of distributions\n",
    "\n",
    "Another use of the term \"parameter\" is as an abstract\n",
    "index that points to a particular distribution in\n",
    "a family of distributions.\n",
    "For instance, we might have a multiset of distributions\n",
    "$\\mathcal{P} = \\{\\mathbb{P}_\\eta\\}_{\\eta \\in \\Theta}$.\n",
    "In that case, $\\eta$ is an index parameter.\n",
    "For index parameters, if for all parameters $\\eta$, $\\nu \\in \\Theta$ such that\n",
    "$\\eta \\ne \\nu$, $\\mathbb{P}_\\eta \\ne \\mathbb{P}_\\nu$, the parameter is said to be _identifiable_.\n",
    "That is, $X$ contains enough information to\n",
    "identify the value of the parameter with arbitrarily high accuracy, given enough\n",
    "observations.\n",
    "Otherwise, the parameter is _non-identifiable_ or _unidentifiable_: the data\n",
    "do not contain enough information to distinguish among different values\n",
    "of the parameter, no matter how many observations are made.\n",
    "\n",
    "\n",
    "#### Special case: location-scale families\n",
    "\n",
    "Many indexed families of distributions are related through the\n",
    "value of their parameter in a particular way. \n",
    "For instance, suppose that the outcome space $\\mathcal{X}$ is a real vector space,\n",
    "so it makes sense to add elements of $\\mathcal{X}$ and to multiply them by scalars.\n",
    "\n",
    "If $X \\sim \\mathbb{P}$, then for any $x \\in \\mathcal{X}$ and $a \\in \\Re \\backslash \\{0\\}$,\n",
    "we could define $\\mathbb{P}_{x,a}$ to be the distribution of $aX+x$.\n",
    "Then $\\{P_{x, a} \\}_{x \\in \\mathcal{X}, a \\in \\Re \\backslash \\{0\\}}$ is a \n",
    "_location-scale family_\n",
    "with parameter $\\theta = (x, a)$\n",
    "As $x$ varies, the probability distribution \"shifts\" its location.\n",
    "As $a$ varies, the probability distribution $P$ is \"stretched\" or re-scaled.\n",
    "The family of univariate normal distributions is a location-scale family over the two-dimensional parameter $\\theta = (\\mu, \\sigma)$ with $\\mu \\in \\Re$, $\\sigma \\in \\Re \\backslash \\{0\\}$.\n",
    "\n",
    "#### Notation for index parameters\n",
    "To keep the notation for index parameters\n",
    "parallel with the notation for functional parameters, we will define $\\theta(\\mathbb{P}) \\equiv \n",
    "\\{ \\eta: \\mathbb{P} = \\mathbb{P}_\\eta\\}$.\n",
    "If $\\theta$ is identifiable, $\\theta(\\mathbb{P})$ is a singleton set; otherwise,\n",
    "it may contain more than one element. \n",
    "\n",
    "### Parametric families of distributions\n",
    "\n",
    "A _parametric family of distributions_ is an indexed collection of probability distributions\n",
    "that depends on the index parameter (which might be multidimensional) in a \n",
    "fixed functional way.\n",
    "(We can think of things like the mean and standard deviation of a normal distribution as either a multidimensional parameter or as a collection of parameters.)\n",
    "\n",
    "Most distributions that have names are parametric families, e.g., Bernoulli (the parameter $p$), Binomial (the two-dimensional parameter $(n, p)$), Geometric ($p$), Hypergeometric (the three-dimensional parameter $(N, G, n)$), Negative Binomial $(p, k)$, Normal $(\\mu, \\sigma)$, Student's $T$ $(\\mu, \\sigma, \\nu)$, continuous uniform (the endpoints of the interval of support, the two-dimensional parameter $(a, b)$), and so on. \n",
    "\n",
    "### Nuisance parameters\n",
    "\n",
    "When the probability distribution of the data depends on a multi-dimensional parameter\n",
    "but only some components of that parameter are of interest, the other components are called _nuisance parameters_. \n",
    "For instance, in estimating the mean of a normal distribution, the\n",
    "variance of the distribution is a nuisance parameter: we don't care what it is,\n",
    "but it affects the probability distribution of the data.\n",
    "\n",
    "Similarly, in estimating a population mean from a stratified sample, the means\n",
    "within the different strata are nuisance parameters.\n",
    "\n",
    "\n",
    "### Abstract parameters\n",
    "\n",
    "For most of the theory in this chapter, $\\theta$ will be an abstract parameter:\n",
    "the development applies to functional parameters, index parameters, parameters of\n",
    "parametric families, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence sets\n",
    "\n",
    "What can we learn about the value of $\\theta(\\mathbb{P})$ from observations?\n",
    "[The chapter on testing](./tests.ipynb) discusses testing hypotheses, including\n",
    "hypotheses about parameters.\n",
    "Here we explore a different approach to quantifying what a sample tells us about\n",
    "$\\theta$: confidence sets.\n",
    "The treatment will be abstract but informal. \n",
    "(For instance, we shall ignore measurability issues.)\n",
    "\n",
    "In an abuse of notation, we will let $\\theta$ denote both the value of a parameter, and\n",
    "the mapping from a distribution to the value of the parameter for that distribution,\n",
    "as if $\\theta$ were a functional parameter even if it is an index parameter (or some other\n",
    "kind of parameter).\n",
    "Thus, $\\theta: \\mathcal{P} \\rightarrow \\Theta$, $\\mathbb{P} \\mapsto \\theta(\\mathbb{P})$.\n",
    "If $\\mathbb{P} = \\mathbb{P}_\\eta$, then $\\theta(\\mathbb{P}) = \\eta$.\n",
    "The set $\\Theta$ will denote the possible values of $\\theta$. \n",
    "Lowercase Greek letters such as $\\eta$ will denote\n",
    "generic elements of $\\Theta$.\n",
    "\n",
    "We shall observe $X \\sim \\mathbb{P}$, where $X$ takes values in the outcome space $\\mathcal{X}$.\n",
    "We do not know $\\mathbb{P}$, but we know that $\\mathbb{P} \\in \\mathcal{P}$, a known set of distributions.\n",
    "Let $\\mathcal{I}(\\cdot)$ be a set-valued function that assigns a subset of $\\Theta$ to each possible observation $x \\in \\mathcal{X}$.\n",
    "For instance, we might observe $X \\sim N(\\theta, 1)$, and $\\mathcal{I}(x)$ might be $[x-c, x+c]$.\n",
    "\n",
    "Fix $\\alpha \\in (0, 1)$.\n",
    "Suppose that for all $\\eta \\in \\Theta$, if $\\theta(\\mathbb{P}) = \\eta$ then\n",
    "\\begin{equation}\n",
    "\\mathbb{P} \\{\\mathcal{I}(X) \\ni \\eta \\} \\ge 1-\\alpha.\n",
    "\\end{equation}\n",
    "Then $\\mathcal{I}(\\cdot)$ is _a $1-\\alpha$ confidence set procedure_ for $\\theta(\\mathbb{P})$.\n",
    "It maps outcomes to sets in such a way that the chance is at least\n",
    "$1-\\alpha$ that the resulting set will contain the true value of the\n",
    "parameter $\\theta(\\mathbb{P})$.\n",
    "\n",
    "If we observe $X=x$, $\\mathcal{I}(x)$ is _a $1-\\alpha$ confidence set for $\\theta$_.\n",
    "The _confidence level_ of the set is $1-\\alpha$.\n",
    "\n",
    "When $\\mathcal{I}(x) \\ni \\theta$, we say that the confidence set _covers_ $\\theta$.\n",
    "The _coverage probability_ of the confidence set $\\mathcal{I}$\n",
    "is \n",
    "\\begin{equation*}\n",
    "\\inf_{\\eta \\in \\Theta} \\inf_{\\mathbb{P} \\in \\mathcal{P} : \\theta(\\mathbb{P}) = \\eta} \\mathbb{P} \\{\\mathcal{I}(X) \\ni \\eta \\}.\n",
    "\\end{equation*}\n",
    "\n",
    "Before the data $X$ are observed, the chance that $\\mathcal{I}(X)$ will contain $\\theta$\n",
    "is the coverage probability, $1-\\alpha$. \n",
    "After the data $X=x$ are observed, the set $\\mathcal{I}(x)$ either\n",
    "does or does not contain $\\theta$: there is nothing random anymore.\n",
    "\n",
    "A _confidence interval_ is a special case of a confidence set, when the set is an interval of real numbers.\n",
    "_One-sided confidence intervals_ are the special case that the confidence set is a semi-infinite interval, i.e., a set of real numbers of the form $(-\\infty, c]$ or $[c, \\infty)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: confidence interval for a Normal mean\n",
    "\n",
    "Suppose $X \\sim N(\\theta, 1)$: $\\theta$ is an index parameter for the (parametric) family of unit variance normal distributions ($\\mathcal{P} \\equiv \\{N(\\eta, 1)\\}_{\\eta \\in \\Re}$) and also a functional parameter, since $\\mathbb{E} X = \\theta$.\n",
    "\n",
    "Define $\\mathcal{I}(x) \\equiv [x - z_{1-\\alpha/2}, x + z_{1-\\alpha/2}]$, where\n",
    "$z_{1-\\alpha/2}$ is the $1-\\alpha/2$ percentile of the standard normal distribution.\n",
    "Then \n",
    "\\begin{equation}\n",
    "   \\mathbb{P}_\\theta \\{ \\mathcal{I}(X) \\ni \\theta \\} = 1-\\alpha\n",
    "\\end{equation}\n",
    "whatever be $\\theta \\in \\Re$.\n",
    "Thus $[x - z_{1-\\alpha/2}, x + z_{1-\\alpha/2}]$ is a $1-\\alpha$\n",
    "confidence interval for $\\theta$.\n",
    "\n",
    "Why is the coverage probability of $[X - z_{1-\\alpha/2}, X + z_{1-\\alpha/2}]$ \n",
    "equal to $1-\\alpha$?\n",
    "\n",
    "The distribution of $X-\\theta$ is a standard normal ($N(0,1)$), so\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}_\\theta  \\{|X-\\theta| \\le z_{1-\\alpha/2} \\} = 1-\\alpha.\n",
    "\\end{equation*}\n",
    "But whenever $|X-\\theta| \\le z_{1-\\alpha/2}$,\n",
    "the interval $[X - z_{1-\\alpha/2}, X + z_{1-\\alpha/2}]$ contains $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duality between hypothesis tests and confidence sets\n",
    "\n",
    "One of the most versatile ways of constructing confidence sets is to _invert_\n",
    "hypothesis tests.\n",
    "\n",
    "Suppose we have a (possibly randomized) family of significance level $\\alpha$ hypothesis tests for all possible values of a parameter $\\theta \\in \\Theta$. \n",
    "That is, for each $\\eta \\in \\Theta$, we have a _test function_ (aka _critical function_)\n",
    "$\\phi_\\eta : \\mathcal{X} \\rightarrow [0, 1]$ such that if $\\theta(\\mathbb{P}) = \\eta$,\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}_{\\mathbb{P}} \\phi_\\eta(X) \\ge 1-\\alpha.\n",
    "\\end{equation*}\n",
    "The test function\n",
    "$\\phi_\\eta(x)$ is the probability of not rejecting the hypothesis $\\theta(\\mathbb{P}) = \\eta$ \n",
    "when $X=x$.\n",
    "When $\\phi_\\eta(X) = 0$, we certainly reject the null; when \n",
    "$\\phi_\\eta(X)=1$, we certainly do not reject the null; values between 0 and 1 correspond to\n",
    "rejecting the null hypothesis with probability $1-\\phi(X)$.\n",
    "The test involves both $X$ and a uniformly distributed random variable $U \\sim U[0,1]$\n",
    "independent of $X$. The test rejects if $U \\ge \\phi(X)$.\n",
    "See [the chapter on hypothesis tests](./tests.ipynb).\n",
    "\n",
    "Consider the set \n",
    "\\begin{equation*}\n",
    "\\mathcal{I}(X,U) \\equiv \\{ \\eta \\in \\Theta : \\phi_\\eta(X) \\ge U \\}.\n",
    "\\end{equation*}\n",
    "That is, $\\mathcal{I}$ is the set of possible parameters $\\eta \\in \\Theta$ for which the corresponding test $\\phi_\\eta$ does not reject the hypothesis that $\\theta(\\mathbb{P}) = \\eta$, for the observed values of $X$ and $U$.\n",
    "(If $\\phi$ can only take the values 0 and 1, i.e., if the test is not randomized, then $\\mathcal{I}$ does not depend on $U$.)\n",
    "\n",
    "**Claim:** $\\mathcal{I}(X,U)$ is a $1-\\alpha$ confidence procedure. That is,\n",
    "whatever the true value of $\\theta(\\mathbb{P})$ happens to be,\n",
    "\\begin{equation}\n",
    "\\mathbb{P} \\{ \\mathcal{I}(X,U) \\ni \\theta(\\mathbb{P}) \\} \\ge 1-\\alpha.\n",
    "\\end{equation}\n",
    "\n",
    "**Proof:** The set \n",
    "$\\mathcal{I}(X,U) \\ni \\theta(\\mathbb{P})$ whenever the test of the null hypothesis that $\\theta(\\mathbb{P}) = \\theta$\n",
    "does not reject, that is, when $\\phi_\\theta(X) \\ge U$.\n",
    "But when $\\theta(\\mathbb{P}) = \\theta$, \n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\{\\phi_\\theta(X) \\ge U\\} = \\mathbb{E}_{\\mathbb{P}} \\phi(X) \\ge 1-\\alpha.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, there are many ways to construct a set of tests $\\{\\phi_\\eta\\}_{\\eta \\in \\Theta}$ with significance level $\\alpha$.\n",
    "Inverting different tests will lead to confidence sets with different properties.\n",
    "\n",
    "It is often possible to design confidence sets that have desirable characteristics--such as avoiding including zero to the extent possible (so that they determine the sign of their parameter), or being on average as small as possible--by inverting suitably chosen tests. \n",
    "See, e.g., [Benjamini, Hochberg, and Stark (1996)](https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1998.10474112#.YGk8ERRKg-Q), [Benjamini and Stark (1996)](https://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476692), and [Benjamini, Hechtlinger, and Stark (2019)](https://arxiv.org/abs/1906.00505)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: confidence interval for Binomial $p$ (known $n$)\n",
    "\n",
    "Suppose we will observe $X \\sim \\mbox{Binom}(n, p)$, where $n$ is known but $p$ is not.\n",
    "We seek a one-sided lower confidence interval for $p$, that is, a set of the form\n",
    "$[f(X,U), \\infty)$ such that for all $q \\in [0, 1]$, if $X \\sim \\mbox{Binom}(n, q)$\n",
    "and $U$ is an independent uniform random variable, then\n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\{ [f(X,U), \\infty) \\ni q \\} \\ge 1-\\alpha.\n",
    "\\end{equation*}\n",
    "Since it is certain that $p \\le 1$, the upper endpoint of the interval can be reduced from $\\infty$ to 1 without sacrificing coverage probability. That is, the same $f$ will satisfy\n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\{ [f(X,U), 1] \\ni q \\} \\ge 1-\\alpha.\n",
    "\\end{equation*}\n",
    "\n",
    "To make such a lower confidence bound, we can invert one-sided hypothesis tests that\n",
    "reject when $X$ is \"too big.\"\n",
    "That is, we want a family of tests of the hypotheses $p = q$ for all $q \\in [0, 1]$\n",
    "that reject for large values of $X$. Such tests give evidence that $p$ is _at least_ a given size.\n",
    "\n",
    "To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests. \n",
    "Because we are basing the confidence intervals on\n",
    "_conservative_ tests, we expect the coverage probability to be greater than $1-\\alpha$.\n",
    "We reject the hypothesis $p = q$ if, on the assumption that $p=q$, the chance that\n",
    "$X$ would be greater than or equal to its observed value is not greater than $\\alpha$.\n",
    "That is, \n",
    "\\begin{equation*}\n",
    "\\phi_q(x) = \\left \\{ \\begin{array}{ll}\n",
    "                      1, & \\sum_{k=x}^n \\binom{n}{k}q^k(1-q)^{n-k} \\ge \\alpha \\\\\n",
    "                      0, & \\mbox{otherwise.}\n",
    "                      \\end{array}\n",
    "            \\right .\n",
    "\\end{equation*}\n",
    "The lower endpoint of the one-sided confidence interval is the smallest value of \n",
    "$q$ for which the\n",
    "corresponding test does not reject:\n",
    "\\begin{equation*}\n",
    "f(x) \\equiv \\min \\{q : \\sum_{k=x}^n \\binom{n}{k}q^k(1-q)^{n-k} \\ge \\alpha \\}.\n",
    "\\end{equation*}\n",
    "Note that the upper tail probability, $\\sum_{k=x}^n \\binom{n}{k}q^k(1-q)^{n-k}$,\n",
    "increases continuously and \n",
    "monotonically as $q$ increases, so finding where it crosses $\\alpha$ is a straightforward\n",
    "root-finding problem.\n",
    "\n",
    "Let's code this up in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import brentq  # Brent's root-finding algorithm\n",
    "from scipy.stats import binom      # the Binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_lower_ci(n, x, cl=0.95):\n",
    "    '''\n",
    "    lower confidence bound for a binomial p\n",
    "    \n",
    "    Assumes x is a draw from a binomial distribution with parameters\n",
    "    n (known) and p (unknown). Finds a lower confidence bound for p \n",
    "    at confidence level cl.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        number of trials, nonnegative integer\n",
    "    x : int\n",
    "        observed number of successes, nonnegative integer not larger than n\n",
    "    cl : float\n",
    "        confidence level, between 0 and 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lb : float\n",
    "        lower confidence bound\n",
    "    '''\n",
    "    assert 0 <= x <= n, 'impossible arguments'\n",
    "    assert 0 < cl < 1, 'silly confidence level'\n",
    "    lb = 0\n",
    "    if x > 0:\n",
    "        lb = brentq(lambda q: binom.sf(x-1,n,q)-(1-cl), 0, 1)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 covered  97.70%\n",
      "0.2 covered  96.78%\n",
      "0.3 covered  95.07%\n",
      "0.4 covered  96.72%\n",
      "0.5 covered  96.84%\n",
      "0.6 covered  97.26%\n",
      "0.7 covered  95.90%\n",
      "0.8 covered  95.13%\n",
      "0.9 covered  96.42%\n"
     ]
    }
   ],
   "source": [
    "# some simulations to test\n",
    "reps = int(10**4)\n",
    "n = 50\n",
    "for p in np.arange(0.1, 1, .1):\n",
    "    cover = 0\n",
    "    xs = binom.rvs(n, p, size=reps)\n",
    "    for x in xs:\n",
    "        cover += (1 if binom_lower_ci(n,x) <= p\n",
    "                 else 0)\n",
    "    print(f'p: {p:.1f} covered: {100*cover/reps : .2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about how you might make a 2-sided confidence interval for $p$ instead of a lower 1-sided confidence interval. \n",
    "There are countless ways of constructing acceptance regions for the underlying tests, as mentioned in the [testing](./tests.ipynb) chapter. \n",
    "For instance, we could trim the same probability $\\alpha/2$ from both tails, or use the acceptance region that contains the fewest outcomes. \n",
    "The latter choice in general will lead to shorter confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: confidence interval for Hypergeometric $G$ (known $N$, $n$)\n",
    "\n",
    "Suppose we will observe $X \\sim \\mbox{Hyper}(N, G, n)$, where $N$ and $n$ are known but $G$ is not.\n",
    "We seek a one-sided lower confidence interval for $G$, that is, a set of the form\n",
    "$[f(X,U), \\infty)$ such that for all $G \\in \\{0, 1, \\ldots, N\\}$, if $X \\sim \\mbox{Hyper}(N, G, n)$\n",
    "and $U$ is an independent uniform random variable, then\n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\{ [f(X,U), \\infty) \\ni G \\} \\ge 1-\\alpha.\n",
    "\\end{equation*}\n",
    "Since it is certain that $G \\le N$, the upper endpoint of the interval can be reduced from $\\infty$ to $N$ without sacrificing coverage probability. That is, the same $f$ will satisfy\n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\{ [f(X,U), N] \\ni q \\} \\ge 1-\\alpha.\n",
    "\\end{equation*}\n",
    "\n",
    "To make such a lower confidence bound, we can invert one-sided hypothesis tests that\n",
    "reject when $X$ is \"too big.\"\n",
    "That is, we want a family of tests of the hypotheses $G = H$ for all $H \\in \\{0, 1, \\ldots, N\\}$\n",
    "that reject for large values of $X$. \n",
    "Such tests give evidence that $G$ is _at least_ a given size.\n",
    "\n",
    "To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests. \n",
    "Because we are basing the confidence intervals on\n",
    "_conservative_ tests, we expect the coverage probability to be greater than $1-\\alpha$.\n",
    "We reject the hypothesis $G = I$ if, on the assumption that $G=I$, the chance that\n",
    "$X$ would be greater than or equal to its observed value is not greater than $\\alpha$.\n",
    "That is, \n",
    "\\begin{equation*}\n",
    "\\phi_q(x) = \\left \\{ \\begin{array}{ll}\n",
    "                      1, & \\sum_{k=x}^n \\frac{\\binom{I}{k}\\binom{N-I}{n-k}}{\\binom{N}{n}} \\ge \\alpha \\\\\n",
    "                      0, & \\mbox{otherwise.}\n",
    "                      \\end{array}\n",
    "            \\right .\n",
    "\\end{equation*}\n",
    "(Of course, we know $G \\ge X$.)\n",
    "The lower endpoint of the one-sided confidence interval is the smallest value of \n",
    "$I$ for which the\n",
    "corresponding test does not reject:\n",
    "\\begin{equation*}\n",
    "f(x) \\equiv \\min \\left \\{I \\in \\{x, x+1, \\ldots, N\\} : \\frac{\\binom{I}{k}\\binom{N-I}{n-k}}{\\binom{N}{n}} \\ge \\alpha \\right \\}.\n",
    "\\end{equation*}\n",
    "Note that the upper tail probability does not increase monotonically as $I$ increases;\n",
    "moreover, because $I$ must be an integer, the optimization problem is discrete,\n",
    "not continuous.\n",
    "Thus standard root-finding methods will _not_ let us find where the tail probability\n",
    "crosses $\\alpha$.\n",
    "Instead, we will use a search.\n",
    "\n",
    "Let's code this up in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypergeom_lower_ci(N, n, x, cl=0.95):\n",
    "    '''\n",
    "    lower confidence bound for a hypergeometric G\n",
    "    \n",
    "    Assumes x is a draw from a hypergeometric distribution with parameters\n",
    "    N (known), n (known), and G (unknown). Finds a lower confidence bound for G \n",
    "    at confidence level cl.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        population size, nonnegative integer\n",
    "    n : int\n",
    "        number of trials, nonnegative integer <= N\n",
    "    x : int\n",
    "        observed number of successes, nonnegative integer not larger than n\n",
    "    cl : float\n",
    "        confidence level, between 0 and 1\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lb : float\n",
    "        lower confidence bound\n",
    "    '''\n",
    "    assert 0 <= x <= n, 'impossible arguments'\n",
    "    assert n <= N, 'impossible sample size'\n",
    "    assert 0 < cl < 1, 'silly confidence level'\n",
    "    lb = x\n",
    "    tail = hypergeom.sf(x-1, N, lb, n)\n",
    "    while tail < (1-cl):\n",
    "        lb += 1\n",
    "        tail = hypergeom.sf(x-1, N, lb, n)\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=20, G=10, n=10: covered  98.82%\n",
      "N=50, G=30, n=20: covered  98.22%\n",
      "N=100, G=25, n=30: covered  97.39%\n"
     ]
    }
   ],
   "source": [
    "NN = [20, 50, 100]\n",
    "nn = [10, 20, 30]\n",
    "GG = [10, 30, 25]\n",
    "reps = int(10**4)\n",
    "\n",
    "for j in range(len(NN)):\n",
    "    cover = 0\n",
    "    xs = hypergeom.rvs(NN[j], GG[j], nn[j], size=reps)\n",
    "    for x in xs:\n",
    "        cover += (1 if hypergeom_lower_ci(NN[j], nn[j], x, cl=0.95) <= GG[j]\n",
    "                 else 0)\n",
    "    print(f'N={NN[j]}, G={GG[j]}, n={nn[j]}: covered {100*cover/reps : .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals from permutation tests\n",
    "\n",
    "### The two-sample problem\n",
    "\n",
    "Recall from the chapter on [hypothesis tests](./tests.ipynb) that the two-sample problem asks whether two groups are unlikely to have resulted from allocating their union randomly into two groups of the observed sizes.\n",
    "That is, we have two groups of data $\\{x_j\\}_{j=1}^n$ and $\\{y_j\\}_{j=1}^m$, and hypothesize that they arose by taking the multiset of values $\\{x_1, \\ldots, x_n, y_1, \\ldots, y_m\\}$ and randomly selecting $n$ of them to comprise the first group, with the remaining $m$ comprising the second group.\n",
    "\n",
    "This problem arises in many contexts, including randomized controlled trials:\n",
    "We have a group of $n+m$ subjects of whom $n$ are selected at random to be the control/placebo group\n",
    "and the other $m$ receive the active treatment.\n",
    "The _strong null hypothesis_ of no treatment effect is as follows: each subject would have had the same response, regardles of whether the subject was assigned to treatment or control.\n",
    "It is as if the response were determined before the assignment to treatment or control occurred. The assignment just reveals the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neyman model for causal inference\n",
    "\n",
    "There are $N$ subjects and $T$ possible treatments.\n",
    "Each subject is represented by a ticket. \n",
    "Ticket $j$ lists $T$ numbers, $(x_{j1}, \\ldots, x_{jT})$.\n",
    "The value $x_{jt}$ is the response subject $j$ will have if assigned the $t$th treatment.\n",
    "(One of the $T$ \"treatments\" might be control or placebo.)\n",
    "\n",
    "This mathematical set up embodies the _non-interference_ assumption, which means that\n",
    "subject $j$'s response depends only on which treatment subject $j$ receives, and not\n",
    "on the treatment other subjects receive.\n",
    "(That is not a good assumption in situations like vaccine trials, where whether one subject\n",
    "becomes infected may depend on which other subjects are vaccinated, if subjects\n",
    "mnay come in contact with each other.)\n",
    "\n",
    "This model is also called the _potential outcomes_ model, because it starts with the\n",
    "_potential_ outcomes each subject will have to each treatment. Assigning a subject to a \n",
    "treatment just reveals the potential outcome that corresponds to that treatment, for that subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _strong_ null hypothesis is that subject by subject, the treatments are the same.\n",
    "That is,\n",
    "\\begin{equation*}\n",
    "x_{j1} = x_{j2} = \\cdots = x_{jT}, \\;\\; j=1, \\ldots, N.\n",
    "\\end{equation*}\n",
    "Different subjects may have different responses ($x_{jt}$ might not equal $x_{kt}$ if $j \\ne k$), but each subject's response is the same regardless of the treatment assigned \n",
    "to that subject.\n",
    "This is the null hypothesis Fisher considered in _The Design of Experiments_ and generally\n",
    "considered the \"correct\" null in practice.\n",
    "\n",
    "Suppose $T=2$: we are comparing two treatments. Suppose we assign $n$ subjects at random\n",
    "to treatment 1 and the other $m = N-n$ to treatment 2.\n",
    "Let $\\{z_j\\}_{j=1}^n$ be the responses of the subjects assigned treatment 1\n",
    "and $\\{y_j\\}_{j=1}^m$ be the responses of the subjects assigned treatment 2.\n",
    "(That is, $z_1 = x_{k1}$ if $k$ is the first subject assigned treatment $1$,\n",
    "and $y_1 = x_{k2}$ if $k$ is the first subject assigned treatment $2$.)\n",
    "Then testing the strong null hypothesis is identical to the two-sample problem:\n",
    "under the strong null, each subject's response would have been the same, regardless\n",
    "of treatment, so allocating subject to treatments and observing their responses\n",
    "is just randomly partitioning a fixed set of $n$ numbers into a group of size $n$ and a group of size $m$.\n",
    "\n",
    "The _weak_ null hypothesis is that on average across subjects, all treatments have the same effect. \n",
    "That is,\n",
    "\\begin{equation*}\n",
    "\\frac{1}{N} \\sum_{j=1}^N x_{j1} = \\frac{1}{N} \\sum_{j=1}^N x_{j2} = \\ldots = \\frac{1}{N} \\sum_{j=1}^N x_{jT}.\n",
    "\\end{equation*}\n",
    "Much of Neyman's work on experiments involves this null hypothesis.\n",
    "The statistical theory is more complex for the weak null hypothesis than for the strong null.\n",
    "\n",
    "The strong null is indeed a stronger hypothesis than the weak null, because if the strong null is true, the weak null must also be true: if two lists are equal, element by element, then their means are equal. \n",
    "But the converse is not true: the weak null can be true even if the strong null is false.\n",
    "For example, for $T=2$ and $N=2$, we might have responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative hypotheses\n",
    "\n",
    "The alternatives considered generally all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative hypotheses: constant multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

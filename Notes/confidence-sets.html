
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Confidence Sets &#8212; Collaborative and Reproducible Data Science</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Collaborative and Reproducible Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Statistics 159/259, Spring 2021 Course Summary
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../schedule.html">
   Statistics 159/259: Weekly Plan
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus.html">
   Syllabus for Statistics 159/259: Reproducible and Collaborative Statistical Data Science
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Homework Assignments
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw01-background.html">
   1. Homework 1. Stats review and intro to Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw02-election-fraud.html">
   2. Homework 2. Election Fraud
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw03-testing.html">
   3. Homework 3: Coding style, docstrings, algorithmic choices, and unit tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw04-phil-sci-covid.html">
   4. Homework 4: Reproducibility, Philosophy of Science, and COVID-19 Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw05-selection-outliers.html">
   5. Homework 5: Selective inference and outlier rejection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw06-cryptorandom-contrib.html">
   6. Homework 6: Cryptorandom - contributing to an open source project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw06-cryptorandom-tips.html">
   7. Some tips for HW06
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Lecture Notes
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   An Idiosyncratic Sample of Applied Statistics
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Lecture Index
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Index/index.html">
   Index of Lectures and Materials
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Notes/confidence-sets.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Notes/confidence-sets.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#this-is-a-rough-work-in-progress">
   This is a rough work in progress!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-parameters">
   Types of Parameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#population-parameters">
     Population parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functional-parameters-of-probability-distributions">
     Functional parameters of probability distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters-as-indices-of-sets-of-distributions">
     Parameters as indices of sets of distributions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#special-case-location-scale-families">
       Special case: location-scale families
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#notation-for-index-parameters">
       Notation for index parameters
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-families-of-distributions">
     Parametric families of distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nuisance-parameters">
     Nuisance parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abstract-parameters">
     Abstract parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Confidence sets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-confidence-interval-for-a-normal-mean">
     Example: confidence interval for a Normal mean
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#duality-between-hypothesis-tests-and-confidence-sets">
   Duality between hypothesis tests and confidence sets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-confidence-interval-for-binomial-p-known-n">
     Example: confidence interval for Binomial
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     (known
     <span class="math notranslate nohighlight">
      \(n\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-confidence-interval-for-hypergeometric-g-known-n-n">
     Example: confidence interval for Hypergeometric
     <span class="math notranslate nohighlight">
      \(G\)
     </span>
     (known
     <span class="math notranslate nohighlight">
      \(N\)
     </span>
     ,
     <span class="math notranslate nohighlight">
      \(n\)
     </span>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-intervals-from-permutation-tests">
   Confidence intervals from permutation tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-two-sample-problem">
     The two-sample problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-hypotheses-constant-shift">
     Alternative hypotheses: constant shift
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-hypotheses-constant-multiple">
     Alternative hypotheses: constant multiple
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section id="confidence-sets">
<h1>Confidence Sets<a class="headerlink" href="#confidence-sets" title="Permalink to this headline">¶</a></h1>
<section id="this-is-a-rough-work-in-progress">
<h2>This is a rough work in progress!<a class="headerlink" href="#this-is-a-rough-work-in-progress" title="Permalink to this headline">¶</a></h2>
</section>
<section id="types-of-parameters">
<h2>Types of Parameters<a class="headerlink" href="#types-of-parameters" title="Permalink to this headline">¶</a></h2>
<p>Many different kinds of things are called “parameters.” Here are several categories.</p>
<section id="population-parameters">
<h3>Population parameters<a class="headerlink" href="#population-parameters" title="Permalink to this headline">¶</a></h3>
<p>Any property of a population may be called a <em>parameter</em>.
Examples include the population mean, percentiles, number of modes, etc.</p>
<p>If the population has more than one “value” per item, e.g., if the population is a group of people each of whom has a height and a weight, then the population correlation between height and weight is a parameter.</p>
<p>Similarly, consider a group of individuals and the values of some quantity (the “response”) for each of those individuals without and with some intervention (notionally, a “treatment”).
The difference between the average response without the intervention and the average response with the intervention is a parameter (the <em>average treatment effect</em>).</p>
<p>If we are sampling at random from a population, the probability distribution of the sample
depends on the values in the population, and thus, in general, on the
values of population parameters.
(It will also depend on the sampling design.)</p>
</section>
<section id="functional-parameters-of-probability-distributions">
<h3>Functional parameters of probability distributions<a class="headerlink" href="#functional-parameters-of-probability-distributions" title="Permalink to this headline">¶</a></h3>
<p>Suppose <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, where <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is a probability distribution on some space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> of possible outcomes.
We assume that <span class="math notranslate nohighlight">\(\mathbb{P} \in \mathcal{P}\)</span>, some known set of possible distributions.</p>
<p>A <em>functional parameter</em> <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> is a function of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.
For instance the (population) mean is a functional parameter:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b776f0a0-859c-420f-9864-2faa0306459a">
<span class="eqno">()<a class="headerlink" href="#equation-b776f0a0-859c-420f-9864-2faa0306459a" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\theta(\mathbb{P}) = \mathbb{E}X \equiv \int_\mathcal{X} x d\mathbb{P}(x).
\end{equation}\]</div>
<p>So are other moments of the probability distribution:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\theta(\mathbb{P}) = \mathbb{E}X^n \equiv \int_\mathcal{X} x^n d\mathbb{P}(x), \;\; n=1, 2, \ldots .
\end{equation*}\]</div>
<p>Other properties of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, such as percentiles of a univariate
distribution, are also functional parameters.
For instance, if <span class="math notranslate nohighlight">\(X\)</span> is a real-valued random variable,
then the <span class="math notranslate nohighlight">\(\alpha\)</span> percentile of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-91b04ad4-0fd1-4f97-b8b9-d0bfd69e4060">
<span class="eqno">()<a class="headerlink" href="#equation-91b04ad4-0fd1-4f97-b8b9-d0bfd69e4060" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\theta(\mathbb{P}) = \inf \left \{x: \int_{-\infty}^x d\mathbb{P}(x) \ge \alpha \right \},
\end{equation}\]</div>
<p>is a functional parameter.</p>
<p>For multivariate distributions, correlations among the components of <span class="math notranslate nohighlight">\(X\)</span>
are functional parameters.</p>
<p>In general, there can be distinct distributions <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> and <span class="math notranslate nohighlight">\(\mathbb{Q}\)</span> such that
<span class="math notranslate nohighlight">\(\mathbb{P} \ne \mathbb{Q}\)</span> but <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta(\mathbb{Q})\)</span>.
For instance there are infinitely many normal distributions with the
same mean (but different variances).</p>
</section>
<section id="parameters-as-indices-of-sets-of-distributions">
<h3>Parameters as indices of sets of distributions<a class="headerlink" href="#parameters-as-indices-of-sets-of-distributions" title="Permalink to this headline">¶</a></h3>
<p>Another use of the term “parameter” is as an abstract
index that points to a particular distribution in
a family of distributions.
For instance, we might have a multiset of distributions
<span class="math notranslate nohighlight">\(\mathcal{P} = \{\mathbb{P}_\eta\}_{\eta \in \Theta}\)</span>.
In that case, <span class="math notranslate nohighlight">\(\eta\)</span> is an index parameter.
For index parameters, if for all parameters <span class="math notranslate nohighlight">\(\eta\)</span>, <span class="math notranslate nohighlight">\(\nu \in \Theta\)</span> such that
<span class="math notranslate nohighlight">\(\eta \ne \nu\)</span>, <span class="math notranslate nohighlight">\(\mathbb{P}_\eta \ne \mathbb{P}_\nu\)</span>, the parameter is said to be <em>identifiable</em>.
That is, <span class="math notranslate nohighlight">\(X\)</span> contains enough information to
identify the value of the parameter with arbitrarily high accuracy, given enough
observations.
Otherwise, the parameter is <em>non-identifiable</em> or <em>unidentifiable</em>: the data
do not contain enough information to distinguish among different values
of the parameter, no matter how many observations are made.</p>
<section id="special-case-location-scale-families">
<h4>Special case: location-scale families<a class="headerlink" href="#special-case-location-scale-families" title="Permalink to this headline">¶</a></h4>
<p>Many indexed families of distributions are related through the
value of their parameter in a particular way.
For instance, suppose that the outcome space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is a real vector space,
so it makes sense to add elements of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and to multiply them by scalars.</p>
<p>If <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, then for any <span class="math notranslate nohighlight">\(x \in \mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(a \in \Re \backslash \{0\}\)</span>,
we could define <span class="math notranslate nohighlight">\(\mathbb{P}_{x,a}\)</span> to be the distribution of <span class="math notranslate nohighlight">\(aX+x\)</span>.
Then <span class="math notranslate nohighlight">\(\{P_{x, a} \}_{x \in \mathcal{X}, a \in \Re \backslash \{0\}}\)</span> is a
<em>location-scale family</em>
with parameter <span class="math notranslate nohighlight">\(\theta = (x, a)\)</span>
As <span class="math notranslate nohighlight">\(x\)</span> varies, the probability distribution “shifts” its location.
As <span class="math notranslate nohighlight">\(a\)</span> varies, the probability distribution <span class="math notranslate nohighlight">\(P\)</span> is “stretched” or re-scaled.
The family of univariate normal distributions is a location-scale family over the two-dimensional parameter <span class="math notranslate nohighlight">\(\theta = (\mu, \sigma)\)</span> with <span class="math notranslate nohighlight">\(\mu \in \Re\)</span>, <span class="math notranslate nohighlight">\(\sigma \in \Re \backslash \{0\}\)</span>.</p>
</section>
<section id="notation-for-index-parameters">
<h4>Notation for index parameters<a class="headerlink" href="#notation-for-index-parameters" title="Permalink to this headline">¶</a></h4>
<p>To keep the notation for index parameters
parallel with the notation for functional parameters, we will define <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) \equiv 
\{ \eta: \mathbb{P} = \mathbb{P}_\eta\}\)</span>.
If <span class="math notranslate nohighlight">\(\theta\)</span> is identifiable, <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> is a singleton set; otherwise,
it may contain more than one element.</p>
</section>
</section>
<section id="parametric-families-of-distributions">
<h3>Parametric families of distributions<a class="headerlink" href="#parametric-families-of-distributions" title="Permalink to this headline">¶</a></h3>
<p>A <em>parametric family of distributions</em> is an indexed collection of probability distributions
that depends on the index parameter (which might be multidimensional) in a
fixed functional way.
(We can think of things like the mean and standard deviation of a normal distribution as either a multidimensional parameter or as a collection of parameters.)</p>
<p>Most distributions that have names are parametric families, e.g., Bernoulli (the parameter <span class="math notranslate nohighlight">\(p\)</span>), Binomial (the two-dimensional parameter <span class="math notranslate nohighlight">\((n, p)\)</span>), Geometric (<span class="math notranslate nohighlight">\(p\)</span>), Hypergeometric (the three-dimensional parameter <span class="math notranslate nohighlight">\((N, G, n)\)</span>), Negative Binomial <span class="math notranslate nohighlight">\((p, k)\)</span>, Normal <span class="math notranslate nohighlight">\((\mu, \sigma)\)</span>, Student’s <span class="math notranslate nohighlight">\(T\)</span> <span class="math notranslate nohighlight">\((\mu, \sigma, \nu)\)</span>, continuous uniform (the endpoints of the interval of support, the two-dimensional parameter <span class="math notranslate nohighlight">\((a, b)\)</span>), and so on.</p>
</section>
<section id="nuisance-parameters">
<h3>Nuisance parameters<a class="headerlink" href="#nuisance-parameters" title="Permalink to this headline">¶</a></h3>
<p>When the probability distribution of the data depends on a multi-dimensional parameter
but only some components of that parameter are of interest, the other components are called <em>nuisance parameters</em>.
For instance, in estimating the mean of a normal distribution, the
variance of the distribution is a nuisance parameter: we don’t care what it is,
but it affects the probability distribution of the data.</p>
<p>Similarly, in estimating a population mean from a stratified sample, the means
within the different strata are nuisance parameters.</p>
</section>
<section id="abstract-parameters">
<h3>Abstract parameters<a class="headerlink" href="#abstract-parameters" title="Permalink to this headline">¶</a></h3>
<p>For most of the theory in this chapter, <span class="math notranslate nohighlight">\(\theta\)</span> will be an abstract parameter:
the development applies to functional parameters, index parameters, parameters of
parametric families, etc.</p>
</section>
</section>
<section id="id1">
<h2>Confidence sets<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>What can we learn about the value of <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> from observations?
<a class="reference internal" href="tests.html"><span class="doc std std-doc">The chapter on testing</span></a> discusses testing hypotheses, including
hypotheses about parameters.
Here we explore a different approach to quantifying what a sample tells us about
<span class="math notranslate nohighlight">\(\theta\)</span>: confidence sets.
The treatment will be abstract but informal.
(For instance, we shall ignore measurability issues.)</p>
<p>In an abuse of notation, we will let <span class="math notranslate nohighlight">\(\theta\)</span> denote both the value of a parameter, and
the mapping from a distribution to the value of the parameter for that distribution,
as if <span class="math notranslate nohighlight">\(\theta\)</span> were a functional parameter even if it is an index parameter (or some other
kind of parameter).
Thus, <span class="math notranslate nohighlight">\(\theta: \mathcal{P} \rightarrow \Theta\)</span>, <span class="math notranslate nohighlight">\(\mathbb{P} \mapsto \theta(\mathbb{P})\)</span>.
If <span class="math notranslate nohighlight">\(\mathbb{P} = \mathbb{P}_\eta\)</span>, then <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>.
The set <span class="math notranslate nohighlight">\(\Theta\)</span> will denote the possible values of <span class="math notranslate nohighlight">\(\theta\)</span>.
Lowercase Greek letters such as <span class="math notranslate nohighlight">\(\eta\)</span> will denote
generic elements of <span class="math notranslate nohighlight">\(\Theta\)</span>.</p>
<p>We shall observe <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> takes values in the outcome space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.
We do not know <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, but we know that <span class="math notranslate nohighlight">\(\mathbb{P} \in \mathcal{P}\)</span>, a known set of distributions.
Let <span class="math notranslate nohighlight">\(\mathcal{I}(\cdot)\)</span> be a set-valued function that assigns a subset of <span class="math notranslate nohighlight">\(\Theta\)</span> to each possible observation <span class="math notranslate nohighlight">\(x \in \mathcal{X}\)</span>.
For instance, we might observe <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> might be <span class="math notranslate nohighlight">\([x-c, x+c]\)</span>.</p>
<p>Fix <span class="math notranslate nohighlight">\(\alpha \in (0, 1)\)</span>.
Suppose that for all <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span>, if <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span> then</p>
<div class="amsmath math notranslate nohighlight" id="equation-8a7c7ad4-7f70-41cd-a089-c7e534d6aa06">
<span class="eqno">()<a class="headerlink" href="#equation-8a7c7ad4-7f70-41cd-a089-c7e534d6aa06" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbb{P} \{\mathcal{I}(X) \ni \eta \} \ge 1-\alpha.
\end{equation}\]</div>
<p>Then <span class="math notranslate nohighlight">\(\mathcal{I}(\cdot)\)</span> is a <em>confidence set procedure</em> for <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span>.
It maps outcomes to sets in such a way that the chance is at least
<span class="math notranslate nohighlight">\(1-\alpha\)</span> that the resulting set will contain the parameter <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span>.</p>
<p>If we observe <span class="math notranslate nohighlight">\(X=x\)</span>, <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> is <em>a <span class="math notranslate nohighlight">\(1-\alpha\)</span> confidence set for <span class="math notranslate nohighlight">\(\theta\)</span></em>.
The <em>confidence level</em> of the set is <span class="math notranslate nohighlight">\(1-\alpha\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(\mathcal{I}(x) \ni \theta\)</span>, we say that the confidence set <em>covers</em> <span class="math notranslate nohighlight">\(\theta\)</span>.
The <em>coverage probability</em> of the confidence set <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>
is <span class="math notranslate nohighlight">\(\mathbb{P} \{\mathcal{I}(X) \ni \theta \}\)</span>.</p>
<p>Before the data <span class="math notranslate nohighlight">\(X\)</span> are observed, the chance that <span class="math notranslate nohighlight">\(\mathcal{I}(X)\)</span> will contain <span class="math notranslate nohighlight">\(\theta\)</span>
is <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
After the data <span class="math notranslate nohighlight">\(X=x\)</span> are observed, the set <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> either
does or does not contain <span class="math notranslate nohighlight">\(\theta\)</span>: there is nothing random anymore.</p>
<p>A <em>confidence interval</em> is a special case of a confidence set, when the set is an interval of real numbers.
<em>One-sided confidence intervals</em> are the special case that the confidence set is a semi-infinite interval, i.e., a set of real numbers of the form <span class="math notranslate nohighlight">\((-\infty, c]\)</span> or <span class="math notranslate nohighlight">\([c, \infty)\)</span>.</p>
<section id="example-confidence-interval-for-a-normal-mean">
<h3>Example: confidence interval for a Normal mean<a class="headerlink" href="#example-confidence-interval-for-a-normal-mean" title="Permalink to this headline">¶</a></h3>
<p>Suppose <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>: <span class="math notranslate nohighlight">\(\theta\)</span> is an index parameter for the (parametric) family of unit variance normal distributions (<span class="math notranslate nohighlight">\(\mathcal{P} \equiv \{N(\eta, 1)\}_{\eta \in \Re}\)</span>) and also a functional parameter, since <span class="math notranslate nohighlight">\(\mathbb{E} X = \theta\)</span>.</p>
<p>Define <span class="math notranslate nohighlight">\(\mathcal{I}(x) \equiv [x - z_{1-\alpha/2}, x + z_{1-\alpha/2}]\)</span>, where
<span class="math notranslate nohighlight">\(z_{1-\alpha/2}\)</span> is the <span class="math notranslate nohighlight">\(1-\alpha/2\)</span> percentile of the standard normal distribution.
Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-9496e9bc-4b73-4b00-a73c-c2e0a7ea8e64">
<span class="eqno">()<a class="headerlink" href="#equation-9496e9bc-4b73-4b00-a73c-c2e0a7ea8e64" title="Permalink to this equation">¶</a></span>\[\begin{equation}
   \mathbb{P}_\theta \{ \mathcal{I}(X) \ni \theta \} = 1-\alpha
\end{equation}\]</div>
<p>whatever be <span class="math notranslate nohighlight">\(\theta \in \Re\)</span>.
Thus <span class="math notranslate nohighlight">\([x - z_{1-\alpha/2}, x + z_{1-\alpha/2}]\)</span> is a <span class="math notranslate nohighlight">\(1-\alpha\)</span>
confidence interval for <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Why is the coverage probability of <span class="math notranslate nohighlight">\([X - z_{1-\alpha/2}, X + z_{1-\alpha/2}]\)</span>
equal to <span class="math notranslate nohighlight">\(1-\alpha\)</span>?</p>
<p>The distribution of <span class="math notranslate nohighlight">\(X-\theta\)</span> is a standard normal (<span class="math notranslate nohighlight">\(N(0,1)\)</span>), so</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_\theta  \{|X-\theta| \le z_{1-\alpha/2} \} = 1-\alpha.
\end{equation*}\]</div>
<p>But whenever <span class="math notranslate nohighlight">\(|X-\theta| \le z_{1-\alpha/2}\)</span>,
the interval <span class="math notranslate nohighlight">\([X - z_{1-\alpha/2}, X + z_{1-\alpha/2}]\)</span> contains <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</section>
</section>
<section id="duality-between-hypothesis-tests-and-confidence-sets">
<h2>Duality between hypothesis tests and confidence sets<a class="headerlink" href="#duality-between-hypothesis-tests-and-confidence-sets" title="Permalink to this headline">¶</a></h2>
<p>One of the most versatile ways of constructing confidence sets is to <em>invert</em>
hypothesis tests.</p>
<p>Suppose we have a (possibly randomized) family of significance level <span class="math notranslate nohighlight">\(\alpha\)</span> hypothesis tests for all possible values of a parameter <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>.
That is, for each <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span>, we have a <em>test function</em> (aka <em>critical function</em>)
<span class="math notranslate nohighlight">\(\phi_\eta : \mathcal{X} \rightarrow [0, 1]\)</span> such that if <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E}_{\mathbb{P}} \phi_\eta(X) \ge 1-\alpha.
\end{equation*}\]</div>
<p>The test function
<span class="math notranslate nohighlight">\(\phi_\eta(x)\)</span> is the probability of not rejecting the hypothesis <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>
when <span class="math notranslate nohighlight">\(X=x\)</span>.
When <span class="math notranslate nohighlight">\(\phi_\eta(X) = 0\)</span>, we certainly reject the null; when
<span class="math notranslate nohighlight">\(\phi_\eta(X)=1\)</span>, we certainly do not reject the null; values between 0 and 1 correspond to
rejecting the null hypothesis with probability <span class="math notranslate nohighlight">\(1-\phi(X)\)</span>.
The test involves both <span class="math notranslate nohighlight">\(X\)</span> and a uniformly distributed random variable <span class="math notranslate nohighlight">\(U \sim U[0,1]\)</span>
independent of <span class="math notranslate nohighlight">\(X\)</span>. The test rejects if <span class="math notranslate nohighlight">\(U \ge \phi(X)\)</span>.
See <a class="reference internal" href="tests.html"><span class="doc std std-doc">the chapter on hypothesis tests</span></a>.</p>
<p>Consider the set</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathcal{I}(X,U) \equiv \{ \eta \in \Theta : \phi_\eta(X) \ge U \}.
\end{equation*}\]</div>
<p>That is, <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> is the set of possible parameters <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span> for which the corresponding test <span class="math notranslate nohighlight">\(\phi_\eta\)</span> does not reject the hypothesis that <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>, for the observed values of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(U\)</span>.
(If <span class="math notranslate nohighlight">\(\phi\)</span> can only take the values 0 and 1, i.e., if the test is not randomized, then <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> does not depend on <span class="math notranslate nohighlight">\(U\)</span>.)</p>
<p><strong>Claim:</strong> <span class="math notranslate nohighlight">\(\mathcal{I}(X,U)\)</span> is a <span class="math notranslate nohighlight">\(1-\alpha\)</span> confidence procedure. That is,
whatever the true value of <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> happens to be,</p>
<div class="amsmath math notranslate nohighlight" id="equation-bfca57cd-7c4a-4189-9994-00a6b71d2124">
<span class="eqno">()<a class="headerlink" href="#equation-bfca57cd-7c4a-4189-9994-00a6b71d2124" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbb{P} \{ \mathcal{I}(X,U) \ni \theta(\mathbb{P}) \} \ge 1-\alpha.
\end{equation}\]</div>
<p><strong>Proof:</strong> The set
<span class="math notranslate nohighlight">\(\mathcal{I}(X,U) \ni \theta(\mathbb{P})\)</span> whenever the test of the null hypothesis that <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta\)</span>
does not reject, that is, when <span class="math notranslate nohighlight">\(\phi_\theta(X) \ge U\)</span>.
But when <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{\phi_\theta(X) \ge U\} = \mathbb{E}_{\mathbb{P}} \phi(X) \ge 1-\alpha.
\end{equation*}\]</div>
<section id="example-confidence-interval-for-binomial-p-known-n">
<h3>Example: confidence interval for Binomial <span class="math notranslate nohighlight">\(p\)</span> (known <span class="math notranslate nohighlight">\(n\)</span>)<a class="headerlink" href="#example-confidence-interval-for-binomial-p-known-n" title="Permalink to this headline">¶</a></h3>
<p>Suppose we will observe <span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, p)\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is known but <span class="math notranslate nohighlight">\(p\)</span> is not.
We seek a one-sided lower confidence interval for <span class="math notranslate nohighlight">\(p\)</span>, that is, a set of the form
<span class="math notranslate nohighlight">\([f(X,U), \infty)\)</span> such that for all <span class="math notranslate nohighlight">\(q \in [0, 1]\)</span>, if <span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, q)\)</span>
and <span class="math notranslate nohighlight">\(U\)</span> is an independent uniform random variable, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), \infty) \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>Since it is certain that <span class="math notranslate nohighlight">\(p \le 1\)</span>, the upper endpoint of the interval can be reduced from <span class="math notranslate nohighlight">\(\infty\)</span> to 1 without sacrificing coverage probability. That is, the same <span class="math notranslate nohighlight">\(f\)</span> will satisfy</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), 1] \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>To make such a lower confidence bound, we can invert one-sided hypothesis tests that
reject when <span class="math notranslate nohighlight">\(X\)</span> is “too big.”
That is, we want a family of tests of the hypotheses <span class="math notranslate nohighlight">\(p = q\)</span> for all <span class="math notranslate nohighlight">\(q \in [0, 1]\)</span>
that reject for large values of <span class="math notranslate nohighlight">\(X\)</span>. Such tests give evidence that <span class="math notranslate nohighlight">\(p\)</span> is <em>at least</em> a given size.</p>
<p>To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests.
Because we are basing the confidence intervals on
<em>conservative</em> tests, we expect the coverage probability to be greater than <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
We reject the hypothesis <span class="math notranslate nohighlight">\(p = q\)</span> if, on the assumption that <span class="math notranslate nohighlight">\(p=q\)</span>, the chance that
<span class="math notranslate nohighlight">\(X\)</span> would be greater than or equal to its observed value is not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>.
That is,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\phi_q(x) = \left \{ \begin{array}{ll}
                      1, &amp; \sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k} \ge \alpha \\
                      0, &amp; \mbox{otherwise}
                      \end{array}
            \right .
\end{equation*}\]</div>
<p>The lower endpoint of the one-sided confidence interval is the smallest value of
<span class="math notranslate nohighlight">\(q\)</span> for which the
corresponding test does not reject:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
f(x) \equiv \min \{q : \sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k} \ge \alpha \}.
\end{equation*}\]</div>
<p>Note that the upper tail probability, <span class="math notranslate nohighlight">\(\sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k}\)</span>,
increases continuously and
monotonically as <span class="math notranslate nohighlight">\(q\)</span> increases, so finding where it crosses <span class="math notranslate nohighlight">\(\alpha\)</span> is a straightforward
root-finding problem.</p>
<p>Let’s code this up in python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">brentq</span>  <span class="c1"># Brent&#39;s root-finding algorithm</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>      <span class="c1"># the Binomial distribution</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">binom_lower_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    lower confidence bound for a binomial p</span>
<span class="sd">    </span>
<span class="sd">    Assumes x is a draw from a binomial distribution with parameters</span>
<span class="sd">    n (known) and p (unknown). Finds a lower confidence bound for p </span>
<span class="sd">    at confidence level cl.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        number of trials, nonnegative integer</span>
<span class="sd">    x : int</span>
<span class="sd">        observed number of successes, nonnegative integer not larger than n</span>
<span class="sd">    cl : float</span>
<span class="sd">        confidence level, between 0 and 1</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        lower confidence bound</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;impossible arguments&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;silly confidence level&#39;</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">brentq</span><span class="p">(</span><span class="k">lambda</span> <span class="n">q</span><span class="p">:</span> <span class="n">binom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">q</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cl</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># some simulations to test</span>
<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
        <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">binom_lower_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">p</span>
                 <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> covered </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span> <span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1 covered  97.70%
0.2 covered  96.78%
0.3 covered  95.07%
0.4 covered  96.72%
0.5 covered  96.84%
0.6 covered  97.26%
0.7 covered  95.90%
0.8 covered  95.13%
0.9 covered  96.42%
</pre></div>
</div>
</div>
</div>
<p>Think about how you might make a 2-sided confidence interval for <span class="math notranslate nohighlight">\(p\)</span> instead of a lower 1-sided confidence interval.
There are countless ways of constructing acceptance regions for the underlying tests, as mentioned in the <a class="reference internal" href="tests.html"><span class="doc std std-doc">testing</span></a> chapter.
For instance, we could trim the same probability <span class="math notranslate nohighlight">\(\alpha/2\)</span> from both tails, or use the acceptance region that contains the fewest outcomes.
The latter choice in general will lead to shorter confidence intervals.</p>
</section>
<section id="example-confidence-interval-for-hypergeometric-g-known-n-n">
<h3>Example: confidence interval for Hypergeometric <span class="math notranslate nohighlight">\(G\)</span> (known <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(n\)</span>)<a class="headerlink" href="#example-confidence-interval-for-hypergeometric-g-known-n-n" title="Permalink to this headline">¶</a></h3>
<p>Suppose we will observe <span class="math notranslate nohighlight">\(X \sim \mbox{Hyper}(N, G, n)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> and <span class="math notranslate nohighlight">\(n\)</span> are known but <span class="math notranslate nohighlight">\(G\)</span> is not.
We seek a one-sided lower confidence interval for <span class="math notranslate nohighlight">\(G\)</span>, that is, a set of the form
<span class="math notranslate nohighlight">\([f(X,U), \infty)\)</span> such that for all <span class="math notranslate nohighlight">\(G \in \{0, 1, \ldots, N\}\)</span>, if <span class="math notranslate nohighlight">\(X \sim \mbox{Hyper}(N, G, n)\)</span>
and <span class="math notranslate nohighlight">\(U\)</span> is an independent uniform random variable, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), \infty) \ni G \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>Since it is certain that <span class="math notranslate nohighlight">\(G \le N\)</span>, the upper endpoint of the interval can be reduced from <span class="math notranslate nohighlight">\(\infty\)</span> to <span class="math notranslate nohighlight">\(N\)</span> without sacrificing coverage probability. That is, the same <span class="math notranslate nohighlight">\(f\)</span> will satisfy</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), N] \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>To make such a lower confidence bound, we can invert one-sided hypothesis tests that
reject when <span class="math notranslate nohighlight">\(X\)</span> is “too big.”
That is, we want a family of tests of the hypotheses <span class="math notranslate nohighlight">\(G = H\)</span> for all <span class="math notranslate nohighlight">\(H \in \{0, 1, \ldots, N\}\)</span>
that reject for large values of <span class="math notranslate nohighlight">\(X\)</span>.
Such tests give evidence that <span class="math notranslate nohighlight">\(G\)</span> is <em>at least</em> a given size.</p>
<p>To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests.
Because we are basing the confidence intervals on
<em>conservative</em> tests, we expect the coverage probability to be greater than <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
We reject the hypothesis <span class="math notranslate nohighlight">\(G = I\)</span> if, on the assumption that <span class="math notranslate nohighlight">\(G=I\)</span>, the chance that
<span class="math notranslate nohighlight">\(X\)</span> would be greater than or equal to its observed value is not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>.
That is,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\phi_q(x) = \left \{ \begin{array}{ll}
                      1, &amp; \sum_{k=x}^n \frac{\binom{I}{k}\binom{N-I}{n-k}}{\binom{N}{n}} \ge \alpha \\
                      0, &amp; \mbox{otherwise.}
                      \end{array}
            \right .
\end{equation*}\]</div>
<p>(Of course, we know <span class="math notranslate nohighlight">\(G \ge X\)</span>.)
The lower endpoint of the one-sided confidence interval is the smallest value of
<span class="math notranslate nohighlight">\(I\)</span> for which the
corresponding test does not reject:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
f(x) \equiv \min \{I \in \{x, x+1, \ldots, N\} : \frac{\binom{I}{k}\binom{N-I}{n-k}}{\binom{N}{n}} \ge \alpha \}.
\end{equation*}\]</div>
<p>Note that the upper tail probability does not increase monotonically as <span class="math notranslate nohighlight">\(I\)</span> increases;
moreover, because <span class="math notranslate nohighlight">\(I\)</span> must be an integer, the optimization problem is discrete,
not continuous.
Thus standard root-finding methods will <em>not</em> let us find where the tail probability
crosses <span class="math notranslate nohighlight">\(\alpha\)</span>.
Instead, we will use a search.</p>
<p>Let’s code this up in python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">hypergeom</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hypergeom_lower_ci</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    lower confidence bound for a hypergeometric G</span>
<span class="sd">    </span>
<span class="sd">    Assumes x is a draw from a hypergeometric distribution with parameters</span>
<span class="sd">    N (known), n (known), and G (unknown). Finds a lower confidence bound for G </span>
<span class="sd">    at confidence level cl.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        population size, nonnegative integer</span>
<span class="sd">    n : int</span>
<span class="sd">        number of trials, nonnegative integer &lt;= N</span>
<span class="sd">    x : int</span>
<span class="sd">        observed number of successes, nonnegative integer not larger than n</span>
<span class="sd">    cl : float</span>
<span class="sd">        confidence level, between 0 and 1</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        lower confidence bound</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;impossible arguments&#39;</span>
    <span class="k">assert</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">,</span> <span class="s1">&#39;impossible sample size&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;silly confidence level&#39;</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">tail</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">tail</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cl</span><span class="p">):</span>
        <span class="n">lb</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">tail</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NN</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">nn</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">GG</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>
<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">NN</span><span class="p">)):</span>
    <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
        <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">hypergeom_lower_ci</span><span class="p">(</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                 <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;N=</span><span class="si">{</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">, G=</span><span class="si">{</span><span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">, n=</span><span class="si">{</span><span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">: covered </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span> <span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N=20, G=10, n=10: covered  98.82%
N=50, G=30, n=20: covered  98.22%
N=100, G=25, n=30: covered  97.39%
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="confidence-intervals-from-permutation-tests">
<h2>Confidence intervals from permutation tests<a class="headerlink" href="#confidence-intervals-from-permutation-tests" title="Permalink to this headline">¶</a></h2>
<section id="the-two-sample-problem">
<h3>The two-sample problem<a class="headerlink" href="#the-two-sample-problem" title="Permalink to this headline">¶</a></h3>
</section>
<section id="alternative-hypotheses-constant-shift">
<h3>Alternative hypotheses: constant shift<a class="headerlink" href="#alternative-hypotheses-constant-shift" title="Permalink to this headline">¶</a></h3>
</section>
<section id="alternative-hypotheses-constant-multiple">
<h3>Alternative hypotheses: constant multiple<a class="headerlink" href="#alternative-hypotheses-constant-multiple" title="Permalink to this headline">¶</a></h3>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Philip Stark and Fernando Pérez<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>
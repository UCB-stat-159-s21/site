
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Confidence Sets &#8212; Collaborative and Reproducible Data Science</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Collaborative and Reproducible Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Statistics 159/259, Spring 2021 Course Summary
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../schedule.html">
   Statistics 159/259: Weekly Plan
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus.html">
   Syllabus for Statistics 159/259: Reproducible and Collaborative Statistical Data Science
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Homework Assignments
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw01-background.html">
   1. Homework 1. Stats review and intro to Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw02-election-fraud.html">
   2. Homework 2. Election Fraud
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw03-testing.html">
   3. Homework 3: Coding style, docstrings, algorithmic choices, and unit tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw04-phil-sci-covid.html">
   4. Homework 4: Reproducibility, Philosophy of Science, and COVID-19 Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw05-selection-outliers.html">
   5. Homework 5: Selective inference and outlier rejection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw06-cryptorandom-contrib.html">
   6. Homework 6: Cryptorandom - contributing to an open source project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Hw/hw07-permute-contrib.html">
   7. Homework 7: Permute - contributing to an open source project
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Lecture Notes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   An Idiosyncratic Sample of Applied Statistics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Lecture Index
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Index/index.html">
   Index of Lectures and Materials
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Notes/confidence-sets.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Notes/confidence-sets.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#this-is-a-rough-work-in-progress">
   This is a rough work in progress!
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-parameters">
   Types of Parameters
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#population-parameters">
     Population parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functional-parameters-of-probability-distributions">
     Functional parameters of probability distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters-as-indices-for-sets-of-distributions">
     Parameters as indices for sets of distributions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#special-case-location-scale-families">
       Special case: location-scale families
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#notation-for-index-parameters">
       Notation for index parameters
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-families-of-distributions">
     Parametric families of distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nuisance-parameters">
     Nuisance parameters
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#abstract-parameters">
     Abstract parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Confidence sets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-confidence-interval-for-a-normal-mean">
     Example: confidence interval for a Normal mean
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#duality-between-hypothesis-tests-and-confidence-sets">
   Duality between hypothesis tests and confidence sets
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-confidence-interval-for-binomial-p-known-n">
     Example: confidence interval for Binomial
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     (known
     <span class="math notranslate nohighlight">
      \(n\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrap-approximate-confidence-intervals">
     Bootstrap approximate confidence intervals
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-approximate-confidence-intervals-for-binomial-p">
     Other approximate confidence intervals for Binomial(
     <span class="math notranslate nohighlight">
      \(p\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-2-confidence-interval-for-hypergeometric-g-known-n-n">
     Example 2: confidence interval for Hypergeometric
     <span class="math notranslate nohighlight">
      \(G\)
     </span>
     (known
     <span class="math notranslate nohighlight">
      \(N\)
     </span>
     ,
     <span class="math notranslate nohighlight">
      \(n\)
     </span>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confidence-intervals-from-permutation-tests">
   Confidence intervals from permutation tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-two-sample-problem">
     The two-sample problem
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="confidence-sets">
<h1>Confidence Sets<a class="headerlink" href="#confidence-sets" title="Permalink to this headline">¶</a></h1>
<div class="section" id="this-is-a-rough-work-in-progress">
<h2>This is a rough work in progress!<a class="headerlink" href="#this-is-a-rough-work-in-progress" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="types-of-parameters">
<h2>Types of Parameters<a class="headerlink" href="#types-of-parameters" title="Permalink to this headline">¶</a></h2>
<p>Many different kinds of things are called “parameters.” Here are several categories.</p>
<div class="section" id="population-parameters">
<h3>Population parameters<a class="headerlink" href="#population-parameters" title="Permalink to this headline">¶</a></h3>
<p>Any property of a population may be called a <em>parameter</em>.
Examples include the population mean, percentiles, number of modes, etc.</p>
<p>If the population has more than one “value” per item, a parameter could involve more than one of them. E.g., if the population is a group of people each of whom has a height and a weight, then the population correlation between height and weight is a parameter.</p>
<p>Similarly, consider a group of individuals and the values of some quantity (the “response”) for each of those individuals without and with some intervention (notionally, a “treatment”).
The difference between the average response without the intervention and the average response with the intervention is a parameter (the <em>average treatment effect</em>).</p>
<p>If we are sampling at random from a population, the probability distribution of the sample
depends on the values in the population, and thus, in general, on the
values of population parameters.
(It will also depend on the sampling design.)</p>
</div>
<div class="section" id="functional-parameters-of-probability-distributions">
<h3>Functional parameters of probability distributions<a class="headerlink" href="#functional-parameters-of-probability-distributions" title="Permalink to this headline">¶</a></h3>
<p>Suppose <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, where <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is a probability distribution on some space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> of possible outcomes.
We assume that <span class="math notranslate nohighlight">\(\mathbb{P} \in \mathcal{P}\)</span>, some known set of possible distributions.</p>
<p>A <em>functional parameter</em> <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> is a function of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>.
For instance the (population) mean is a functional parameter:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d283ee6b-7699-407f-9b2a-7c2d4cc7c1ed">
<span class="eqno">()<a class="headerlink" href="#equation-d283ee6b-7699-407f-9b2a-7c2d4cc7c1ed" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\theta(\mathbb{P}) = \mathbb{E}X \equiv \int_\mathcal{X} x d\mathbb{P}(x).
\end{equation}\]</div>
<p>So are other moments of the probability distribution:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\theta(\mathbb{P}) = \mathbb{E}X^n \equiv \int_\mathcal{X} x^n d\mathbb{P}(x), \;\; n=1, 2, \ldots .
\end{equation*}\]</div>
<p>Other properties of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, such as percentiles of a univariate
distribution, are also functional parameters.
For instance, if <span class="math notranslate nohighlight">\(X\)</span> is a real-valued random variable,
then the <span class="math notranslate nohighlight">\(\alpha\)</span> percentile of <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-c89f0ee5-6cfc-4640-9a40-c47a4d7f5450">
<span class="eqno">()<a class="headerlink" href="#equation-c89f0ee5-6cfc-4640-9a40-c47a4d7f5450" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\theta(\mathbb{P}) = \inf \left \{x: \int_{-\infty}^x d\mathbb{P}(x) \ge \alpha \right \},
\end{equation}\]</div>
<p>is a functional parameter.</p>
<p>For multivariate distributions, correlations among the components of <span class="math notranslate nohighlight">\(X\)</span>
are functional parameters.</p>
<p>In general, there can be distinct distributions <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> and <span class="math notranslate nohighlight">\(\mathbb{Q}\)</span> such that
<span class="math notranslate nohighlight">\(\mathbb{P} \ne \mathbb{Q}\)</span> but <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta(\mathbb{Q})\)</span>.
For instance there are infinitely many normal distributions with the
same mean (but different variances).</p>
</div>
<div class="section" id="parameters-as-indices-for-sets-of-distributions">
<h3>Parameters as indices for sets of distributions<a class="headerlink" href="#parameters-as-indices-for-sets-of-distributions" title="Permalink to this headline">¶</a></h3>
<p>Another use of the term “parameter” is as an abstract
index that points to a particular distribution in
a family of distributions.
For instance, we might have a multiset of distributions
<span class="math notranslate nohighlight">\(\mathcal{P} = \{\mathbb{P}_\eta\}_{\eta \in \Theta}\)</span>.
In that case, <span class="math notranslate nohighlight">\(\eta\)</span> is an index parameter.
For index parameters, if for all parameters <span class="math notranslate nohighlight">\(\eta\)</span>, <span class="math notranslate nohighlight">\(\nu \in \Theta\)</span> such that
<span class="math notranslate nohighlight">\(\eta \ne \nu\)</span>, <span class="math notranslate nohighlight">\(\mathbb{P}_\eta \ne \mathbb{P}_\nu\)</span>, the parameter is said to be <em>identifiable</em>.
That is, <span class="math notranslate nohighlight">\(X\)</span> contains enough information to
identify the value of the parameter with arbitrarily high accuracy, given enough
observations.
Otherwise, the parameter is <em>non-identifiable</em> or <em>unidentifiable</em>: the data
do not contain enough information to distinguish among different values
of the parameter, no matter how many observations are made.</p>
<div class="section" id="special-case-location-scale-families">
<h4>Special case: location-scale families<a class="headerlink" href="#special-case-location-scale-families" title="Permalink to this headline">¶</a></h4>
<p>Many indexed families of distributions are related through the
value of their parameter in a particular way.
For instance, suppose that the outcome space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is a real vector space,
so it makes sense to add elements of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and to multiply them by scalars.</p>
<p>If <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, then for any <span class="math notranslate nohighlight">\(x \in \mathcal{X}\)</span> and <span class="math notranslate nohighlight">\(a \in \Re \backslash \{0\}\)</span>,
we could define <span class="math notranslate nohighlight">\(\mathbb{P}_{x,a}\)</span> to be the distribution of <span class="math notranslate nohighlight">\(aX+x\)</span>.
Then <span class="math notranslate nohighlight">\(\{P_{x, a} \}_{x \in \mathcal{X}, a \in \Re \backslash \{0\}}\)</span> is a
<em>location-scale family</em>
with parameter <span class="math notranslate nohighlight">\(\theta = (x, a)\)</span>
As <span class="math notranslate nohighlight">\(x\)</span> varies, the probability distribution “shifts” its location.
As <span class="math notranslate nohighlight">\(a\)</span> varies, the probability distribution <span class="math notranslate nohighlight">\(P\)</span> is “stretched” or re-scaled.
The family of univariate normal distributions is a location-scale family over the two-dimensional parameter <span class="math notranslate nohighlight">\(\theta = (\mu, \sigma)\)</span> with <span class="math notranslate nohighlight">\(\mu \in \Re\)</span>, <span class="math notranslate nohighlight">\(\sigma \in \Re \backslash \{0\}\)</span>.</p>
</div>
<div class="section" id="notation-for-index-parameters">
<h4>Notation for index parameters<a class="headerlink" href="#notation-for-index-parameters" title="Permalink to this headline">¶</a></h4>
<p>To keep the notation for index parameters
parallel with the notation for functional parameters, we will define <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) \equiv 
\{ \eta: \mathbb{P} = \mathbb{P}_\eta\}\)</span>.
If <span class="math notranslate nohighlight">\(\theta\)</span> is identifiable, <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> is a singleton set; otherwise,
it may contain more than one element.</p>
</div>
</div>
<div class="section" id="parametric-families-of-distributions">
<h3>Parametric families of distributions<a class="headerlink" href="#parametric-families-of-distributions" title="Permalink to this headline">¶</a></h3>
<p>A <em>parametric family of distributions</em> is an indexed collection of probability distributions
that depends on the index parameter (which might be multidimensional) in a
fixed functional way.
(We can think of things like the mean and standard deviation of a normal distribution as either a multidimensional parameter or as a collection of parameters.)</p>
<p>Most distributions that have names are parametric families, e.g., Bernoulli (the parameter <span class="math notranslate nohighlight">\(p\)</span>), Binomial (the two-dimensional parameter <span class="math notranslate nohighlight">\((n, p)\)</span>), Geometric (<span class="math notranslate nohighlight">\(p\)</span>), Hypergeometric (the three-dimensional parameter <span class="math notranslate nohighlight">\((N, G, n)\)</span>), Negative Binomial <span class="math notranslate nohighlight">\((p, k)\)</span>, Normal <span class="math notranslate nohighlight">\((\mu, \sigma)\)</span>, Student’s <span class="math notranslate nohighlight">\(T\)</span> <span class="math notranslate nohighlight">\((\mu, \sigma, \nu)\)</span>, continuous uniform (the endpoints of the interval of support, the two-dimensional parameter <span class="math notranslate nohighlight">\((a, b)\)</span>), and so on.</p>
</div>
<div class="section" id="nuisance-parameters">
<h3>Nuisance parameters<a class="headerlink" href="#nuisance-parameters" title="Permalink to this headline">¶</a></h3>
<p>When the probability distribution of the data depends on a multi-dimensional parameter
but only some components of that parameter are of interest, the other components are called <em>nuisance parameters</em>.
For instance, in estimating the mean of a normal distribution, the
variance of the distribution is a nuisance parameter: we don’t care what it is,
but it affects the probability distribution of the data.</p>
<p>Similarly, in estimating a population mean from a stratified sample, the means
within the different strata are nuisance parameters.</p>
</div>
<div class="section" id="abstract-parameters">
<h3>Abstract parameters<a class="headerlink" href="#abstract-parameters" title="Permalink to this headline">¶</a></h3>
<p>For most of the theory in this chapter, <span class="math notranslate nohighlight">\(\theta\)</span> will be an abstract parameter:
the development applies to functional parameters, index parameters, parameters of
parametric families, etc.</p>
</div>
</div>
<div class="section" id="id1">
<h2>Confidence sets<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>What can we learn about the value of <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> from observations?
<a class="reference internal" href="tests.html"><span class="doc std std-doc">The chapter on testing</span></a> discusses testing hypotheses, including
hypotheses about parameters.
Here we explore a different approach to quantifying what a sample tells us about
<span class="math notranslate nohighlight">\(\theta\)</span>: confidence sets.
The treatment will be abstract but informal.
(For instance, we shall ignore measurability issues.)</p>
<p>In an abuse of notation, we will let <span class="math notranslate nohighlight">\(\theta\)</span> denote both the value of a parameter, and
the mapping from a distribution to the value of the parameter for that distribution,
as if <span class="math notranslate nohighlight">\(\theta\)</span> were a functional parameter even if it is an index parameter (or some other
kind of parameter).
Thus, <span class="math notranslate nohighlight">\(\theta: \mathcal{P} \rightarrow \Theta\)</span>, <span class="math notranslate nohighlight">\(\mathbb{P} \mapsto \theta(\mathbb{P})\)</span>.
If <span class="math notranslate nohighlight">\(\mathbb{P} = \mathbb{P}_\eta\)</span>, then <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>.
The set <span class="math notranslate nohighlight">\(\Theta\)</span> will denote the possible values of <span class="math notranslate nohighlight">\(\theta\)</span>.
Lowercase Greek letters such as <span class="math notranslate nohighlight">\(\eta\)</span> will denote
generic elements of <span class="math notranslate nohighlight">\(\Theta\)</span>.</p>
<p>We shall observe <span class="math notranslate nohighlight">\(X \sim \mathbb{P}\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> takes values in the outcome space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.
We do not know <span class="math notranslate nohighlight">\(\mathbb{P}\)</span>, but we know that <span class="math notranslate nohighlight">\(\mathbb{P} \in \mathcal{P}\)</span>, a known set of distributions.
Let <span class="math notranslate nohighlight">\(\mathcal{I}(\cdot)\)</span> be a set-valued function that assigns a subset of <span class="math notranslate nohighlight">\(\Theta\)</span> to each possible observation <span class="math notranslate nohighlight">\(x \in \mathcal{X}\)</span>.
For instance, we might observe <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> might be <span class="math notranslate nohighlight">\([x-c, x+c]\)</span>.</p>
<p>Fix <span class="math notranslate nohighlight">\(\alpha \in (0, 1)\)</span>.
Suppose that for all <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span>, if <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span> then</p>
<div class="amsmath math notranslate nohighlight" id="equation-1d636344-489a-4483-a309-469217aa1d5b">
<span class="eqno">()<a class="headerlink" href="#equation-1d636344-489a-4483-a309-469217aa1d5b" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbb{P} \{\mathcal{I}(X) \ni \eta \} \ge 1-\alpha.
\end{equation}\]</div>
<p>Then <span class="math notranslate nohighlight">\(\mathcal{I}(\cdot)\)</span> is <em>a <span class="math notranslate nohighlight">\(1-\alpha\)</span> confidence set procedure</em> for <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span>.
It maps outcomes to sets in such a way that the chance is at least
<span class="math notranslate nohighlight">\(1-\alpha\)</span> that the resulting set will contain the true value of the
parameter <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span>.</p>
<p>If we observe <span class="math notranslate nohighlight">\(X=x\)</span>, <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> is <em>a <span class="math notranslate nohighlight">\(1-\alpha\)</span> confidence set for <span class="math notranslate nohighlight">\(\theta\)</span></em>.
The <em>confidence level</em> of the set is <span class="math notranslate nohighlight">\(1-\alpha\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(\mathcal{I}(x) \ni \theta\)</span>, we say that the confidence set <em>covers</em> <span class="math notranslate nohighlight">\(\theta\)</span>.
The <em>coverage probability</em> of the confidence set procedure <span class="math notranslate nohighlight">\(\mathcal{I}\)</span>
is</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\inf_{\eta \in \Theta} \inf_{\mathbb{P} \in \mathcal{P} : \theta(\mathbb{P}) = \eta} \mathbb{P} \{\mathcal{I}(X) \ni \eta \}.
\end{equation*}\]</div>
<p>Before the data <span class="math notranslate nohighlight">\(X\)</span> are observed, the chance that <span class="math notranslate nohighlight">\(\mathcal{I}(X)\)</span> will contain <span class="math notranslate nohighlight">\(\theta\)</span>
is the coverage probability, <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
After the data <span class="math notranslate nohighlight">\(X=x\)</span> are observed, the set <span class="math notranslate nohighlight">\(\mathcal{I}(x)\)</span> either
does or does not contain <span class="math notranslate nohighlight">\(\theta\)</span>: there is nothing random anymore.</p>
<p>A <em>confidence interval</em> is a special case of a confidence set, when the set is an interval of real numbers.
<em>One-sided confidence intervals</em> are the special case that the confidence set is a semi-infinite interval, i.e., a set of real numbers of the form <span class="math notranslate nohighlight">\((-\infty, c]\)</span> or <span class="math notranslate nohighlight">\([c, \infty)\)</span>.</p>
<div class="section" id="example-confidence-interval-for-a-normal-mean">
<h3>Example: confidence interval for a Normal mean<a class="headerlink" href="#example-confidence-interval-for-a-normal-mean" title="Permalink to this headline">¶</a></h3>
<p>Suppose <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>: <span class="math notranslate nohighlight">\(\theta\)</span> is an index parameter for the (parametric) family of unit variance normal distributions (<span class="math notranslate nohighlight">\(\mathcal{P} \equiv \{N(\eta, 1)\}_{\eta \in \Re}\)</span>) and also a functional parameter, since <span class="math notranslate nohighlight">\(\mathbb{E} X = \theta\)</span>.</p>
<p>Define <span class="math notranslate nohighlight">\(\mathcal{I}(x) \equiv [x - z_{1-\alpha/2}, x + z_{1-\alpha/2}]\)</span>, where
<span class="math notranslate nohighlight">\(z_{1-\alpha/2}\)</span> is the <span class="math notranslate nohighlight">\(1-\alpha/2\)</span> percentile of the standard normal distribution.
Then</p>
<div class="amsmath math notranslate nohighlight" id="equation-60679ed6-c41d-4eee-99fe-13192f9fbddc">
<span class="eqno">()<a class="headerlink" href="#equation-60679ed6-c41d-4eee-99fe-13192f9fbddc" title="Permalink to this equation">¶</a></span>\[\begin{equation}
   \mathbb{P}_\theta \{ \mathcal{I}(X) \ni \theta \} = 1-\alpha
\end{equation}\]</div>
<p>whatever be <span class="math notranslate nohighlight">\(\theta \in \Re\)</span>.
Thus <span class="math notranslate nohighlight">\([x - z_{1-\alpha/2}, x + z_{1-\alpha/2}]\)</span> is a <span class="math notranslate nohighlight">\(1-\alpha\)</span>
confidence interval for <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Why is the coverage probability of <span class="math notranslate nohighlight">\([X - z_{1-\alpha/2}, X + z_{1-\alpha/2}]\)</span>
equal to <span class="math notranslate nohighlight">\(1-\alpha\)</span>?</p>
<p>The distribution of <span class="math notranslate nohighlight">\(X-\theta\)</span> is a standard normal (<span class="math notranslate nohighlight">\(N(0,1)\)</span>), so</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P}_\theta  \{|X-\theta| \le z_{1-\alpha/2} \} = 1-\alpha.
\end{equation*}\]</div>
<p>But whenever <span class="math notranslate nohighlight">\(|X-\theta| \le z_{1-\alpha/2}\)</span>,
the interval <span class="math notranslate nohighlight">\([X - z_{1-\alpha/2}, X + z_{1-\alpha/2}]\)</span> contains <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
</div>
<div class="section" id="duality-between-hypothesis-tests-and-confidence-sets">
<h2>Duality between hypothesis tests and confidence sets<a class="headerlink" href="#duality-between-hypothesis-tests-and-confidence-sets" title="Permalink to this headline">¶</a></h2>
<p>One of the most versatile ways of constructing confidence sets is to <em>invert</em>
hypothesis tests.</p>
<p>Suppose we have a (possibly randomized) family of significance level <span class="math notranslate nohighlight">\(\alpha\)</span> hypothesis tests for all possible values of a parameter <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>.
That is, for each <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span>, we have a <em>test function</em> (aka <em>critical function</em>)
<span class="math notranslate nohighlight">\(\phi_\eta : \mathcal{X} \rightarrow [0, 1]\)</span> such that if <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{E}_{\mathbb{P}} \phi_\eta(X) \ge 1-\alpha.
\end{equation*}\]</div>
<p>The test function
<span class="math notranslate nohighlight">\(\phi_\eta(x)\)</span> is the probability of not rejecting the hypothesis <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>
when <span class="math notranslate nohighlight">\(X=x\)</span>.
When <span class="math notranslate nohighlight">\(\phi_\eta(X) = 0\)</span>, we certainly reject the null; when
<span class="math notranslate nohighlight">\(\phi_\eta(X)=1\)</span>, we certainly do not reject the null; values between 0 and 1 correspond to
rejecting the null hypothesis with probability <span class="math notranslate nohighlight">\(1-\phi(X)\)</span>.
The test involves both <span class="math notranslate nohighlight">\(X\)</span> and a uniformly distributed random variable <span class="math notranslate nohighlight">\(U \sim U[0,1]\)</span>
independent of <span class="math notranslate nohighlight">\(X\)</span>. The test rejects if <span class="math notranslate nohighlight">\(U \ge \phi(X)\)</span>.
See <a class="reference internal" href="tests.html"><span class="doc std std-doc">the chapter on hypothesis tests</span></a>.</p>
<p>Consider the set</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathcal{I}(X,U) \equiv \{ \eta \in \Theta : \phi_\eta(X) &gt; U \}.
\end{equation*}\]</div>
<p>That is, <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> is the set of possible parameters <span class="math notranslate nohighlight">\(\eta \in \Theta\)</span> for which the corresponding test <span class="math notranslate nohighlight">\(\phi_\eta\)</span> does not reject the hypothesis that <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \eta\)</span>, for the observed values of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(U\)</span>.
(If <span class="math notranslate nohighlight">\(\phi\)</span> can only take the values 0 and 1, i.e., if the test is not randomized, then <span class="math notranslate nohighlight">\(\mathcal{I}\)</span> does not depend on <span class="math notranslate nohighlight">\(U\)</span>.)</p>
<p><strong>Claim:</strong> <span class="math notranslate nohighlight">\(\mathcal{I}(X,U)\)</span> is a <span class="math notranslate nohighlight">\(1-\alpha\)</span> confidence procedure. That is,
whatever the true value of <span class="math notranslate nohighlight">\(\theta(\mathbb{P})\)</span> happens to be,</p>
<div class="amsmath math notranslate nohighlight" id="equation-a0ed9436-aa44-4501-a9cf-c719d87353fc">
<span class="eqno">()<a class="headerlink" href="#equation-a0ed9436-aa44-4501-a9cf-c719d87353fc" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbb{P} \{ \mathcal{I}(X,U) \ni \theta(\mathbb{P}) \} \ge 1-\alpha.
\end{equation}\]</div>
<p><strong>Proof:</strong> The set
<span class="math notranslate nohighlight">\(\mathcal{I}(X,U) \ni \theta(\mathbb{P})\)</span> whenever the test of the null hypothesis that <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta\)</span>
does not reject, that is, when <span class="math notranslate nohighlight">\(\phi_\theta(X) \ge U\)</span>.
But when <span class="math notranslate nohighlight">\(\theta(\mathbb{P}) = \theta\)</span>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{\phi_\theta(X) \ge U\} = \mathbb{E}_{\mathbb{P}} \phi(X) \ge 1-\alpha.
\end{equation*}\]</div>
<p>In general, there are many ways to construct a set of tests <span class="math notranslate nohighlight">\(\{\phi_\eta\}_{\eta \in \Theta}\)</span> with significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.
Inverting different tests will lead to confidence sets with different properties.
As a simple example, inverting 1-sided tests for a real parameter will give a 1-seded confidence interval for the parameter, while inverting 2-sided tests will yield a 2-sided confidence interval.</p>
<p>It is often possible to design confidence sets that have desirable characteristics–such as avoiding including zero to the extent possible (so that they determine the sign of their parameter), or being on average as small as possible–by inverting suitably chosen tests.
See, e.g., <a class="reference external" href="https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1998.10474112#.YGk8ERRKg-Q">Benjamini, Hochberg, and Stark (1996)</a>; <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1996.10476692">Benjamini and Stark (1996)</a>;
<a class="reference external" href="https://projecteuclid.org/journals/bernoulli/volume-11/issue-4/Minimax-expected-measure-confidence-sets-for-restricted-location-parameters/10.3150/bj/1126126761.full">Evans, Hansen, and Stark (2005)</a>; and <a class="reference external" href="https://arxiv.org/abs/1906.00505">Benjamini, Hechtlinger, and Stark (2019)</a>.</p>
<div class="section" id="example-confidence-interval-for-binomial-p-known-n">
<h3>Example: confidence interval for Binomial <span class="math notranslate nohighlight">\(p\)</span> (known <span class="math notranslate nohighlight">\(n\)</span>)<a class="headerlink" href="#example-confidence-interval-for-binomial-p-known-n" title="Permalink to this headline">¶</a></h3>
<p>Suppose we will observe <span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, p)\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is known but <span class="math notranslate nohighlight">\(p\)</span> is not.
We seek a one-sided lower confidence interval for <span class="math notranslate nohighlight">\(p\)</span>, that is, a set of the form
<span class="math notranslate nohighlight">\([f(X,U), \infty)\)</span> such that for all <span class="math notranslate nohighlight">\(q \in [0, 1]\)</span>, if <span class="math notranslate nohighlight">\(X \sim \mbox{Binom}(n, q)\)</span>
and <span class="math notranslate nohighlight">\(U\)</span> is an independent uniform random variable, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), \infty) \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>Since it is certain that <span class="math notranslate nohighlight">\(p \le 1\)</span>, the upper endpoint of the interval can be reduced from <span class="math notranslate nohighlight">\(\infty\)</span> to 1 without sacrificing coverage probability. That is, the same <span class="math notranslate nohighlight">\(f\)</span> will satisfy</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), 1] \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>To make such a lower confidence bound, we can invert one-sided hypothesis tests that
reject when <span class="math notranslate nohighlight">\(X\)</span> is “too big.”
That is, we want a family of tests of the hypotheses <span class="math notranslate nohighlight">\(p = q\)</span> for all <span class="math notranslate nohighlight">\(q \in [0, 1]\)</span>
that reject for large values of <span class="math notranslate nohighlight">\(X\)</span>. Such tests give evidence that <span class="math notranslate nohighlight">\(p\)</span> is <em>at least</em> a given size.</p>
<p>To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests.
Because we are basing the confidence intervals on
<em>conservative</em> tests, we expect the coverage probability to be greater than <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
We reject the hypothesis <span class="math notranslate nohighlight">\(p = q\)</span> if, on the assumption that <span class="math notranslate nohighlight">\(p=q\)</span>, the chance that
<span class="math notranslate nohighlight">\(X\)</span> would be greater than or equal to its observed value is not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>.
That is,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\phi_q(x) = \left \{ \begin{array}{ll}
                      1, &amp; \sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k} \ge \alpha \\
                      0, &amp; \mbox{otherwise.}
                      \end{array}
            \right .
\end{equation*}\]</div>
<p>The lower endpoint of the one-sided confidence interval is the smallest value of
<span class="math notranslate nohighlight">\(q\)</span> for which the
corresponding test does not reject:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
f(x) \equiv \min \left \{q \in [0, 1]: \sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k} \ge \alpha \right \}.
\end{equation*}\]</div>
<p>Note that the upper tail probability, <span class="math notranslate nohighlight">\(\sum_{k=x}^n \binom{n}{k}q^k(1-q)^{n-k}\)</span>,
increases continuously and
monotonically as <span class="math notranslate nohighlight">\(q\)</span> increases, so finding where it crosses <span class="math notranslate nohighlight">\(\alpha\)</span> is a straightforward
root-finding problem.</p>
<p>Let’s code this up in python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">brentq</span>  <span class="c1"># Brent&#39;s root-finding algorithm</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>      <span class="c1"># the Binomial distribution</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">binom_lower_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    lower confidence bound for a binomial p</span>
<span class="sd">    </span>
<span class="sd">    Assumes x is a draw from a binomial distribution with parameters</span>
<span class="sd">    n (known) and p (unknown). Finds a lower confidence bound for p </span>
<span class="sd">    at confidence level cl.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        number of trials, nonnegative integer</span>
<span class="sd">    x : int</span>
<span class="sd">        observed number of successes, nonnegative integer not larger than n</span>
<span class="sd">    cl : float</span>
<span class="sd">        confidence level, between 0 and 1</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        lower confidence bound</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;impossible arguments&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;silly confidence level&#39;</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lb</span> <span class="o">=</span> <span class="n">brentq</span><span class="p">(</span><span class="k">lambda</span> <span class="n">q</span><span class="p">:</span> <span class="n">binom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">q</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cl</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># some simulations to test the confidence intervals</span>
<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">n: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">]:</span>
        <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
            <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">binom_lower_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">p</span>
                 <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;p: </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> covered: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span> <span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>   
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n: 10
p: 0.01 covered:  99.60%
p: 0.05 covered:  98.91%
p: 0.10 covered:  98.69%
p: 0.20 covered:  97.02%
p: 0.40 covered:  98.81%
p: 0.50 covered:  99.18%
p: 0.70 covered:  97.18%
p: 0.90 covered:  100.00%
p: 0.95 covered:  100.00%
p: 0.99 covered:  100.00%

n: 50
p: 0.01 covered:  98.54%
p: 0.05 covered:  96.44%
p: 0.10 covered:  97.55%
p: 0.20 covered:  97.01%
p: 0.40 covered:  96.78%
p: 0.50 covered:  96.55%
p: 0.70 covered:  95.63%
p: 0.90 covered:  96.69%
p: 0.95 covered:  100.00%
p: 0.99 covered:  100.00%

n: 100
p: 0.01 covered:  98.27%
p: 0.05 covered:  97.24%
p: 0.10 covered:  96.04%
p: 0.20 covered:  96.50%
p: 0.40 covered:  95.58%
p: 0.50 covered:  95.93%
p: 0.70 covered:  95.42%
p: 0.90 covered:  97.57%
p: 0.95 covered:  96.35%
p: 0.99 covered:  100.00%
</pre></div>
</div>
</div>
</div>
<p>Think about how you might make a 2-sided confidence interval for <span class="math notranslate nohighlight">\(p\)</span> instead of a lower 1-sided confidence interval.
There are countless ways of constructing acceptance regions for the underlying tests, as mentioned in the <a class="reference internal" href="tests.html"><span class="doc std std-doc">testing</span></a> chapter.
For instance, we could trim the same probability <span class="math notranslate nohighlight">\(\alpha/2\)</span> from both tails, or use the acceptance region that contains the fewest outcomes.
The latter choice in general will lead to shorter confidence intervals.
This approach is due to <a class="reference external" href="https://www.jstor.org/stable/2333026">Sterne (1954)</a>.</p>
<p>Let’s implement Sterne’s approach now. The development is analogous to the randomized hypergeometric test in <span class="xref myst">the chapter on testing</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>

<span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># decorate the function to cache the results </span>
                          <span class="c1"># of calls to the function</span>
<span class="k">def</span> <span class="nf">binom_accept</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">randomized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Acceptance region for a randomized binomial test</span>
<span class="sd">    </span>
<span class="sd">    If randomized==True, find the acceptance region for a randomized, exact </span>
<span class="sd">    level-alpha test of the null hypothesis X~Binomial(n,p). </span>
<span class="sd">    The acceptance region is the smallest possible. (And not, for instance, symmetric.)</span>

<span class="sd">    If randomized==False, find the smallest conservative acceptance region.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : integer</span>
<span class="sd">        number of independent trials</span>
<span class="sd">    p : float</span>
<span class="sd">        probability of success in each trial</span>
<span class="sd">    alpha : float</span>
<span class="sd">        desired significance level  </span>
<span class="sd">    ramndomized : Boolean</span>
<span class="sd">        return randomized exact test or conservative non-randomized test?</span>
<span class="sd">  </span>
<span class="sd">    Returns</span>
<span class="sd">    --------</span>
<span class="sd">    If randomized:</span>
<span class="sd">    I : list</span>
<span class="sd">        values for which the test never rejects</span>
<span class="sd">    J : list </span>
<span class="sd">        values for which the test sometimes rejects</span>
<span class="sd">    gamma : float</span>
<span class="sd">        probability the test does not reject when the value is in J</span>
<span class="sd">    </span>
<span class="sd">    If not randomized:</span>
<span class="sd">    I : list</span>
<span class="sd">        values for which the test does not reject</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;bad significance level&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">I</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                    <span class="c1"># start with all possible outcomes (then remove some)</span>
    <span class="n">pmf</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>         <span class="c1"># &quot;frozen&quot; binomial pmf</span>
    <span class="n">bottom</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># smallest outcome still in I</span>
    <span class="n">top</span> <span class="o">=</span> <span class="n">n</span>                        <span class="c1"># largest outcome still in I</span>
    <span class="n">J</span> <span class="o">=</span> <span class="p">[]</span>                         <span class="c1"># outcomes for which the test is randomized</span>
    <span class="n">p_J</span> <span class="o">=</span> <span class="mi">0</span>                        <span class="c1"># probability of outcomes for which test is randomized</span>
    <span class="n">p_tail</span> <span class="o">=</span> <span class="mi">0</span>                     <span class="c1"># probability of outcomes excluded from I</span>
    <span class="k">while</span> <span class="n">p_tail</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>          <span class="c1"># need to remove outcomes from the acceptance region</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
        <span class="n">pt</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">top</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">pb</span> <span class="o">&lt;</span> <span class="n">pt</span><span class="p">:</span>                <span class="c1"># the smaller possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
            <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">pb</span> <span class="o">&gt;</span> <span class="n">pt</span><span class="p">:</span>              <span class="c1"># the larger possibility has smaller probability</span>
            <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">top</span><span class="p">]</span>
            <span class="n">p_J</span> <span class="o">=</span> <span class="n">pt</span>
            <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>                      
            <span class="k">if</span> <span class="n">bottom</span> <span class="o">&lt;</span> <span class="n">top</span><span class="p">:</span>       <span class="c1"># the two possibilities have equal probability</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">,</span> <span class="n">top</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span><span class="o">+</span><span class="n">pt</span>
                <span class="n">bottom</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">top</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>                  <span class="c1"># there is only one possibility left</span>
                <span class="n">J</span> <span class="o">=</span> <span class="p">[</span><span class="n">bottom</span><span class="p">]</span>
                <span class="n">p_J</span> <span class="o">=</span> <span class="n">pb</span>
                <span class="n">bottom</span> <span class="o">+=</span><span class="mi">1</span>
        <span class="n">p_tail</span> <span class="o">+=</span> <span class="n">p_J</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">J</span><span class="p">:</span>                <span class="c1"># remove outcomes from acceptance region</span>
            <span class="n">I</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
    <span class="n">return_val</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">randomized</span><span class="p">:</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_tail</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">/</span><span class="n">p_J</span>     <span class="c1"># probability of accepting H_0 when X in J </span>
                                       <span class="c1"># to get exact level alpha</span>
        <span class="n">return_val</span> <span class="o">=</span> <span class="n">I</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">gamma</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">while</span> <span class="n">p_tail</span> <span class="o">&gt;</span> <span class="n">alpha</span><span class="p">:</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">J</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>            <span class="c1"># move the outcome into the acceptance region</span>
            <span class="n">p_tail</span> <span class="o">-=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">I</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
        <span class="n">return_val</span> <span class="o">=</span> <span class="n">I</span>
    <span class="k">return</span> <span class="n">return_val</span> 


<span class="k">def</span> <span class="nf">binom_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mi">10</span><span class="o">**-</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    two-sided confidence bound for a binomial p</span>
<span class="sd">    </span>
<span class="sd">    Assumes x is a draw from a binomial distribution with parameters</span>
<span class="sd">    n (known) and p (unknown). Finds a confidence interval for p </span>
<span class="sd">    at confidence level cl by inverting conservative tests</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n : int</span>
<span class="sd">        number of trials, nonnegative integer</span>
<span class="sd">    x : int</span>
<span class="sd">        observed number of successes, nonnegative integer not larger than n</span>
<span class="sd">    cl : float</span>
<span class="sd">        confidence level, between 1/2 and 1</span>
<span class="sd">    eps : float in (0, 1)</span>
<span class="sd">        resolution of the grid search</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        lower confidence bound</span>
<span class="sd">    ub : float</span>
<span class="sd">        upper confidence bound</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;impossible arguments&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;silly confidence level&#39;</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">cl</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">while</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">binom_accept</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">randomized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">lb</span> <span class="o">+=</span> <span class="n">eps</span>
        <span class="n">lb</span> <span class="o">-=</span> <span class="n">eps</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">while</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">binom_accept</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">ub</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">randomized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">ub</span> <span class="o">-=</span> <span class="n">eps</span>
        <span class="n">ub</span> <span class="o">+=</span> <span class="n">eps</span>
    <span class="k">return</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cl</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">eps</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**-</span><span class="mi">4</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">n: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">]:</span>
        <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mean_width</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="n">binom_ci</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="n">cl</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span>
            <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>             
                      <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">mean_width</span> <span class="o">+=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean_width</span> <span class="o">/=</span> <span class="n">reps</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;p: </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> covered: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">% mean width: </span><span class="si">{</span><span class="n">mean_width</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n: 10
p: 0.01 covered: 99.65% mean width: 0.31
p: 0.05 covered: 98.84% mean width: 0.36
p: 0.10 covered: 98.86% mean width: 0.41
p: 0.20 covered: 96.80% mean width: 0.48
p: 0.40 covered: 98.23% mean width: 0.54
p: 0.50 covered: 97.95% mean width: 0.55
p: 0.70 covered: 96.03% mean width: 0.52
p: 0.90 covered: 98.82% mean width: 0.41
p: 0.95 covered: 98.94% mean width: 0.36
p: 0.99 covered: 99.55% mean width: 0.31

n: 50
p: 0.01 covered: 98.69% mean width: 0.09
p: 0.05 covered: 95.98% mean width: 0.13
p: 0.10 covered: 96.95% mean width: 0.17
p: 0.20 covered: 94.79% mean width: 0.22
p: 0.40 covered: 95.42% mean width: 0.27
p: 0.50 covered: 96.89% mean width: 0.27
p: 0.70 covered: 96.00% mean width: 0.25
p: 0.90 covered: 97.19% mean width: 0.17
p: 0.95 covered: 96.08% mean width: 0.14
p: 0.99 covered: 98.73% mean width: 0.09

n: 100
p: 0.01 covered: 98.07% mean width: 0.05
p: 0.05 covered: 96.73% mean width: 0.09
p: 0.10 covered: 95.53% mean width: 0.12
p: 0.20 covered: 95.56% mean width: 0.16
p: 0.40 covered: 96.06% mean width: 0.19
p: 0.50 covered: 96.62% mean width: 0.20
p: 0.70 covered: 95.43% mean width: 0.18
p: 0.90 covered: 95.51% mean width: 0.12
p: 0.95 covered: 96.53% mean width: 0.09
p: 0.99 covered: 98.22% mean width: 0.05
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bootstrap-approximate-confidence-intervals">
<h3>Bootstrap approximate confidence intervals<a class="headerlink" href="#bootstrap-approximate-confidence-intervals" title="Permalink to this headline">¶</a></h3>
<p>The bootstrap approximates sampling from a population by sampling with replacement from a sample from the population. That is, it approximates the population distribution by the empirical distribution of the observed sample, which is
the nonparametric maximum likelihood estimate of the population distribution</p>
<p>The bootstrap is commonly used to estimate the variability of an estimator of a functional parameter. It generally does a good job of estimating things like the variance of an estimator.</p>
<p>It can also be used to construct approximate confidence intervals in a variety of ways, including the <em>percentile method</em>, which approximates percentiles of an estimator from percentiles of the resampling distribution of the estimator. However, this generally is not a good approximation.</p>
<p>Let’s code it up and see.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">boot_ci</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bootstrap approximate confidence interval for a functional parameter</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : array-like</span>
<span class="sd">        original sample</span>
<span class="sd">    estimator : callable</span>
<span class="sd">        function defined on the empirical distribution of a sample.</span>
<span class="sd">        Applying it to the population distribution would give the</span>
<span class="sd">        true value of the parameter of interest. Applying it to a </span>
<span class="sd">        sample yields an estimator of the parameter of interest</span>
<span class="sd">    cl : float in (0,1)</span>
<span class="sd">        confidence level</span>
<span class="sd">    reps : int, nonnegative</span>
<span class="sd">        number of bootstrap samples to use</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        estimated lower confidene bound</span>
<span class="sd">    ub : float</span>
<span class="sd">        estimated upper confidence bound</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randomstate</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prng</span> <span class="o">=</span> <span class="n">random_state</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">estimates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reps</span><span class="p">):</span>
        <span class="n">estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">estimator</span><span class="p">(</span><span class="n">prng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
    <span class="n">estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">estimates</span><span class="p">)</span>
    <span class="n">tail</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cl</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">tail</span><span class="p">)</span>
    <span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">tail</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
<span class="n">reps_boot</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">12345678</span>
<span class="n">prng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">n: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">]:</span>
        <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mean_width</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">xs</span> <span class="o">=</span> <span class="n">binom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="n">boot_ci</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">reps</span><span class="o">=</span><span class="n">reps_boot</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">prng</span><span class="p">)</span>
            <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>             
                      <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">mean_width</span> <span class="o">+=</span> <span class="n">bounds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">bounds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mean_width</span> <span class="o">/=</span> <span class="n">reps</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;p: </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> covered: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span> <span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">% mean width: </span><span class="si">{</span><span class="n">mean_width</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n: 10
p: 0.01 covered:  8.50% mean width: 0.03
p: 0.05 covered:  39.10% mean width: 0.13
p: 0.10 covered:  65.20% mean width: 0.25
p: 0.20 covered:  88.20% mean width: 0.41
p: 0.40 covered:  91.70% mean width: 0.56
p: 0.50 covered:  97.30% mean width: 0.58
p: 0.70 covered:  96.50% mean width: 0.52
p: 0.90 covered:  64.90% mean width: 0.25
p: 0.95 covered:  38.00% mean width: 0.13
p: 0.99 covered:  8.80% mean width: 0.03

n: 50
p: 0.01 covered:  38.20% mean width: 0.03
p: 0.05 covered:  91.00% mean width: 0.10
p: 0.10 covered:  96.60% mean width: 0.16
p: 0.20 covered:  94.70% mean width: 0.21
p: 0.40 covered:  95.10% mean width: 0.27
p: 0.50 covered:  96.30% mean width: 0.27
p: 0.70 covered:  96.90% mean width: 0.25
p: 0.90 covered:  96.30% mean width: 0.16
p: 0.95 covered:  89.90% mean width: 0.10
p: 0.99 covered:  38.40% mean width: 0.03

n: 100
p: 0.01 covered:  62.90% mean width: 0.03
p: 0.05 covered:  96.80% mean width: 0.08
p: 0.10 covered:  94.90% mean width: 0.11
p: 0.20 covered:  95.30% mean width: 0.15
p: 0.40 covered:  95.10% mean width: 0.19
p: 0.50 covered:  94.90% mean width: 0.19
p: 0.70 covered:  95.40% mean width: 0.18
p: 0.90 covered:  95.00% mean width: 0.11
p: 0.95 covered:  95.30% mean width: 0.08
p: 0.99 covered:  63.80% mean width: 0.03
</pre></div>
</div>
</div>
</div>
<p>As you can see, the coverage probability of bootstrap percentile confidence intervals can be
much lower than their nominal level (here, as low as about 9% when they should be 95%). Where their coverage is about right, their average width is comparable to the average width of the conservative intervals derived by inverting two-sided tests.</p>
<p>This example is a fairly simple situation: estimating the mean of a population of zeros and ones from a random sample with replacement. In more complicated examples, bootstrap confidence intervals generally do not attain their nominal level.
There is a substantial body of work on how to improve the coverage of bootstrap CIs.
<em>Pre-pivoting</em> can help substantially. See <a class="reference external" href="https://www.jstor.org/stable/2336685?seq=1">Beran (1987)</a>.</p>
</div>
<div class="section" id="other-approximate-confidence-intervals-for-binomial-p">
<h3>Other approximate confidence intervals for Binomial(<span class="math notranslate nohighlight">\(p\)</span>)<a class="headerlink" href="#other-approximate-confidence-intervals-for-binomial-p" title="Permalink to this headline">¶</a></h3>
<p>There are many approximate methods for binomial confidence intervals, for instance, based on the normal approximation or the normal approximation to a transformation of the data.
They generally do not attain their nominal confidence level, even for modest sample sizes,
and their coverage probability varies erratically as <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(p\)</span> vary. See <a class="reference external" href="https://www.jstor.org/stable/2676784?seq=1">Brown, Cai, and DasGupta (2001)</a></p>
</div>
<div class="section" id="example-2-confidence-interval-for-hypergeometric-g-known-n-n">
<h3>Example 2: confidence interval for Hypergeometric <span class="math notranslate nohighlight">\(G\)</span> (known <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(n\)</span>)<a class="headerlink" href="#example-2-confidence-interval-for-hypergeometric-g-known-n-n" title="Permalink to this headline">¶</a></h3>
<p>Suppose we will observe <span class="math notranslate nohighlight">\(X \sim \mbox{Hyper}(N, G, n)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> and <span class="math notranslate nohighlight">\(n\)</span> are known but <span class="math notranslate nohighlight">\(G\)</span> is not.
We seek a one-sided lower confidence interval for <span class="math notranslate nohighlight">\(G\)</span>, that is, a set of the form
<span class="math notranslate nohighlight">\([f(X,U), \infty)\)</span> such that for all <span class="math notranslate nohighlight">\(G \in \{0, 1, \ldots, N\}\)</span>, if <span class="math notranslate nohighlight">\(X \sim \mbox{Hyper}(N, G, n)\)</span>
and <span class="math notranslate nohighlight">\(U\)</span> is an independent uniform random variable, then</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), \infty) \ni G \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>Since it is certain that <span class="math notranslate nohighlight">\(G \le N\)</span>, the upper endpoint of the interval can be reduced from <span class="math notranslate nohighlight">\(\infty\)</span> to <span class="math notranslate nohighlight">\(N\)</span> without sacrificing coverage probability. That is, the same <span class="math notranslate nohighlight">\(f\)</span> will satisfy</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\mathbb{P} \{ [f(X,U), N] \ni q \} \ge 1-\alpha.
\end{equation*}\]</div>
<p>To make such a lower confidence bound, we can invert one-sided hypothesis tests that
reject when <span class="math notranslate nohighlight">\(X\)</span> is “too big.”
That is, we want a family of tests of the hypotheses <span class="math notranslate nohighlight">\(G = H\)</span> for all <span class="math notranslate nohighlight">\(H \in \{0, 1, \ldots, N\}\)</span>
that reject for large values of <span class="math notranslate nohighlight">\(X\)</span>.
Such tests give evidence that <span class="math notranslate nohighlight">\(G\)</span> is <em>at least</em> a given size.</p>
<p>To keep things simple, we will use conservative non-randomized tests rather than exact randomized tests.
Because we are basing the confidence intervals on
<em>conservative</em> tests, we expect the coverage probability to be greater than <span class="math notranslate nohighlight">\(1-\alpha\)</span>.
We reject the hypothesis <span class="math notranslate nohighlight">\(G = I\)</span> if, on the assumption that <span class="math notranslate nohighlight">\(G=I\)</span>, the chance that
<span class="math notranslate nohighlight">\(X\)</span> would be greater than or equal to its observed value is not greater than <span class="math notranslate nohighlight">\(\alpha\)</span>.
That is,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\phi_q(x) = \left \{ \begin{array}{ll}
                      1, &amp; \sum_{k=x}^n \frac{\binom{I}{k}\binom{N-I}{n-k}}{\binom{N}{n}} \ge \alpha \\
                      0, &amp; \mbox{otherwise.}
                      \end{array}
            \right .
\end{equation*}\]</div>
<p>(Of course, we know <span class="math notranslate nohighlight">\(G \ge X\)</span>.)
The lower endpoint of the one-sided confidence interval is the smallest value of
<span class="math notranslate nohighlight">\(I\)</span> for which the
corresponding test does not reject:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
f(x) \equiv \min \left \{I \in \{x, x+1, \ldots, N\} : \frac{\binom{I}{k}\binom{N-I}{n-k}}{\binom{N}{n}} \ge \alpha \right \}.
\end{equation*}\]</div>
<p>Note that the upper tail probability does not increase monotonically as <span class="math notranslate nohighlight">\(I\)</span> increases;
moreover, because <span class="math notranslate nohighlight">\(I\)</span> must be an integer, the optimization problem is discrete,
not continuous.
Thus standard root-finding methods will <em>not</em> let us find where the tail probability
crosses <span class="math notranslate nohighlight">\(\alpha\)</span>.
Instead, we will use a search.</p>
<p>Let’s code this up in python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">hypergeom</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hypergeom_lower_ci</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    lower confidence bound for a hypergeometric G</span>
<span class="sd">    </span>
<span class="sd">    Assumes x is a draw from a hypergeometric distribution with parameters</span>
<span class="sd">    N (known), n (known), and G (unknown). Finds a lower confidence bound for G </span>
<span class="sd">    at confidence level cl.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    N : int</span>
<span class="sd">        population size, nonnegative integer</span>
<span class="sd">    n : int</span>
<span class="sd">        number of trials, nonnegative integer &lt;= N</span>
<span class="sd">    x : int</span>
<span class="sd">        observed number of successes, nonnegative integer &lt;= n</span>
<span class="sd">    cl : float</span>
<span class="sd">        confidence level, between 0 and 1</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    lb : float</span>
<span class="sd">        lower confidence bound</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;impossible arguments&#39;</span>
    <span class="k">assert</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">,</span> <span class="s1">&#39;impossible sample size&#39;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">cl</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;silly confidence level&#39;</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">tail</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">tail</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">cl</span><span class="p">):</span>
        <span class="n">lb</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">tail</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NN</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">nn</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">GG</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>
<span class="n">reps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">)</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">NN</span><span class="p">)):</span>
    <span class="n">cover</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">hypergeom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">reps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">:</span>
        <span class="n">cover</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">hypergeom_lower_ci</span><span class="p">(</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">cl</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                 <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;N=</span><span class="si">{</span><span class="n">NN</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">, G=</span><span class="si">{</span><span class="n">GG</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">, n=</span><span class="si">{</span><span class="n">nn</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s1">: covered </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cover</span><span class="o">/</span><span class="n">reps</span> <span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N=20, G=10, n=10: covered  98.83%
N=50, G=30, n=20: covered  97.92%
N=100, G=25, n=30: covered  97.78%
</pre></div>
</div>
</div>
</div>
<p>We can make two-sided confidence bounds for <span class="math notranslate nohighlight">\(G\)</span> by inverting two-sided tests, such as those given in the <a class="reference internal" href="tests.html"><span class="doc std std-doc">chapter on testing</span></a>.
Recall that we discussed two different constructions of two-sided tests there, one based on trimming the same probability from each tail, and one based on minimizing the number of outcomes in the acceptance region.</p>
</div>
</div>
<div class="section" id="confidence-intervals-from-permutation-tests">
<h2>Confidence intervals from permutation tests<a class="headerlink" href="#confidence-intervals-from-permutation-tests" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-two-sample-problem">
<h3>The two-sample problem<a class="headerlink" href="#the-two-sample-problem" title="Permalink to this headline">¶</a></h3>
<p>Recall from the chapter on <a class="reference internal" href="tests.html"><span class="doc std std-doc">hypothesis tests</span></a> that the two-sample problem asks whether two groups plausibly resulted from allocating their union randomly into two groups of their observed sizes.</p>
<p>That is, we have two groups of data, <span class="math notranslate nohighlight">\(\{x_j\}_{j=1}^n\)</span> and <span class="math notranslate nohighlight">\(\{y_j\}_{j=1}^m\)</span>, and hypothesize that they arose by taking the multiset of <span class="math notranslate nohighlight">\(n+m\)</span> values <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_n, y_1, \ldots, y_m\}\)</span> and randomly selecting <span class="math notranslate nohighlight">\(n\)</span> items to comprise the first group, with the remaining <span class="math notranslate nohighlight">\(m\)</span> comprising the second group.</p>
<p>This problem arises in many contexts, including randomized controlled trials:
We have a group of <span class="math notranslate nohighlight">\(n+m\)</span> subjects of whom <span class="math notranslate nohighlight">\(n\)</span> are selected at random to be the control/placebo group
and the other <span class="math notranslate nohighlight">\(m\)</span> receive the active treatment.
The <em>strong null hypothesis</em> of no treatment effect is that each subject would have had the same response, no matter which treatment the subject was assigned.
It is as if the response were determined before the assignment occurred.
The assignment just reveals the response corresponding to the assigned treatment.</p>
<p>Thus, testing the strong null hypothesis is an instance of the two-sample problem: did the two sets of values plausibly arise from dividing a single set of values at random into two groups by simple random sampling?</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Notes"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Philip Stark and Fernando Pérez<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>
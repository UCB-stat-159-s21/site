{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neyman \"potential outcomes\" model for causal inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $N$ subjects and $T$ possible treatments.\n",
    "Each subject is represented by a ticket. \n",
    "Ticket $j$ lists $T$ numbers, $(x_{j0}, \\ldots, x_{jT-1})$.\n",
    "The value $x_{jt}$ is the response subject $j$ will have if assigned to treatment $t$.\n",
    "(Treatment $0$ is commonly control or placebo.)\n",
    "\n",
    "This mathematical set up embodies the _non-interference_ assumption, which means that\n",
    "subject $j$'s response depends only on which treatment subject $j$ receives, and not\n",
    "on the treatment other subjects receive.\n",
    "(That is not a good assumption in situations like vaccine trials, where whether one subject\n",
    "becomes infected may depend on which other subjects are vaccinated, if subjects\n",
    "may come in contact with each other.)\n",
    "\n",
    "This model is also called the _potential outcomes_ model, because it starts with the\n",
    "_potential_ outcomes each subject will have to each treatment. \n",
    "Assigning a subject to a \n",
    "treatment just reveals the potential outcome that corresponds to that treatment, for that subject. \n",
    "This model was introduced by Jerzy Neyman, the founder of the U.C. Berkeley Department of Statistics, in a 1923 paper in Polish [translated into English in 1990](https://projecteuclid.org/journals/statistical-science/volume-5/issue-4/On-the-Application-of-Probability-Theory-to-Agricultural-Experiments-Essay/10.1214/ss/1177012031.full).\n",
    "It was popularized by Donald Rubin in the 1970s and 1980s.\n",
    "\n",
    "There are generalizations of this model, including one in which the \"potential outcomes\" are random, rather than deterministic, but their distributions are fixed before assignment to treatment: if subject $j$ is assigned treatment $t$, a draw from the distribution $\\mathbb{P}_{jt}$ is observed. \n",
    "Draws for different subjects are independent.\n",
    "We shall see an example of this when we discuss [nuisance parameters](./nuisance.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null hypotheses for the Neyman model\n",
    "\n",
    "The _strong_ null hypothesis is that subject by subject, the effect of\n",
    "all $T$ treatments is the same.\n",
    "That is,\n",
    "\\begin{equation*}\n",
    "x_{j0} = x_{j1} = \\cdots = x_{jT-1}, \\;\\; j=1, \\ldots, N.\n",
    "\\end{equation*}\n",
    "Different subjects may have different responses ($x_{jt}$ might not equal $x_{kt}$ if $j \\ne k$), but each subject's response is the same regardless of the treatment assigned \n",
    "to that subject.\n",
    "This is the null hypothesis Fisher considered in _The Design of Experiments_ and which\n",
    "he generally considered the \"correct\" null in practice.\n",
    "\n",
    "Suppose $T=2$: we are comparing two treatments. Suppose we assign $n$ subjects at random\n",
    "to treatment 0 and the other $m = N-n$ to treatment 1.\n",
    "Let $\\{z_j\\}_{j=1}^n$ be the responses of the subjects assigned treatment 0\n",
    "and $\\{y_j\\}_{j=1}^m$ be the responses of the subjects assigned treatment 1.\n",
    "(That is, $z_1 = x_{k0}$ if $k$ is the first subject assigned treatment $0$,\n",
    "and $y_1 = x_{k1}$ if $k$ is the first subject assigned treatment $1$.)\n",
    "Then testing the strong null hypothesis is identical to the _two-sample problem_:\n",
    "under the strong null, each subject's response would have been the same, regardless\n",
    "of treatment, so allocating subject to treatments and observing their responses\n",
    "is just randomly partitioning a fixed set of $n$ numbers into a group of size $n$ and a group of size $m$.\n",
    "\n",
    "The _weak_ null hypothesis is that on average across subjects, all treatments have the same effect. \n",
    "That is,\n",
    "\\begin{equation*}\n",
    "\\frac{1}{N} \\sum_{j=1}^N x_{j0} = \\frac{1}{N} \\sum_{j=1}^N x_{j1} = \\ldots = \\frac{1}{N} \\sum_{j=1}^N x_{jT-1}.\n",
    "\\end{equation*}\n",
    "Much of Neyman's work on experiments involves this null hypothesis.\n",
    "The statistical theory is more complex for the weak null hypothesis than for the strong null.\n",
    "\n",
    "The strong null is indeed a stronger hypothesis than the weak null, because if the strong null is true, the weak null must also be true: if $T$ lists are equal, element by element, then their means are equal. \n",
    "But the converse is not true: the weak null can be true even if the strong null is false.\n",
    "For example, for $T=2$ and $N=2$, we might have potential responses $(0, 1)$ for subject 1 and $(1,0)$ for subject 2. The effect of treatment is to increase subject 1's response from 0 to 1 and to decrease subject 2's response from 1 to 0.\n",
    "The treatment affects both subjects, but the average effect of treatment is the same: the average response across subjects is 1/2, with or without treatment.\n",
    "\n",
    "If we can test the weak null, we can also make inferences about the _average treatment effect_. If we can only test the strong null, in general we have to make assumptions about how treatment affects responses in order to make inferences about the average treatment effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative hypotheses in the Neyman model\n",
    "\n",
    "#### Constant shift\n",
    "\n",
    "For example, if we assume that the effect of treatment is to shift every subject's response by the same amount, then we can use a test of the strong null to make inferences about that constant effect.\n",
    "In symbols, this alternative states that there is some number $\\Delta$\n",
    "such that $x_{j1} = x_{j0}+\\Delta$ for all subjects $j$.\n",
    "\n",
    "Again, once the original data are observed, this hypothesis completely specifies the probability distribution of the data: we know what subject $j$'s response would have been had the subject been assigned the other treatment. If the subject was assigned treatment 0, the response would have been larger by $\\Delta$ if the subject had been assigned treatment 1 instead. if the subject was assigned treatment 1, the response would have been smaller by $\\Delta$ if the subject had been assigned treatment 0 instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tractable alternative hypotheses\n",
    "\n",
    "A more general alternative is that $x_{j1} = f(x_{j0})$ for some strictly monotonic (and thus invertible) function $f$. \n",
    "A simple example is that treatment multiplies the response by a constant.\n",
    "\n",
    "In some contexts, it can be reasonable to assume that treatment can only help, that is that $x_{j1} \\ge x_{j0}$, without specifying a functional relationship between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the strong null hypothesis\n",
    "\n",
    "Under the strong null that the treatment makes no difference whatsoever--as if \n",
    "the response had been predetermined before assignment to treatment or control--the null distribution of any test statistic is completely determined once the data have\n",
    "been observed: we know what the data would have been for any other random assignment, namely, the same. \n",
    "And we know the chance that each of those possible datasets would have resulted from\n",
    "the experiment, since we know how subjects were assigned at random to treatments.\n",
    "\n",
    "For alternatives that allow us to find $x_{j0}$ from $x_{j1}$ and vice versa,\n",
    "the alternative also completely determines the \n",
    "probability distribution of any test statistic, once the data have been observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two treatments, binary responses.\n",
    " \n",
    "Imagine testing whether a vaccine prevents a disease.\n",
    "We assign a random sample of $n$ of the $N$ subjects to receive treatment 1;\n",
    "the other $N-n$ receive a placebo, treatment 0.\n",
    "Let $W_j$ denote the treatment assigned to subject $j$, so $\\sum_{j=1}^N W_j = n$.\n",
    "After some time has passed, we observe \n",
    "\\begin{equation*}\n",
    "X_j := (1-W_j) x_{j0} + W_j x_{j1}, \\;\\; j=1, \\ldots, N.\n",
    "\\end{equation*}\n",
    "These are random variables, but the only source of randomness is $\\{W_j\\}$, the \n",
    "treatment assignment variables.\n",
    "\n",
    "The total number of infections among the vaccinated is\n",
    "\\begin{equation*}\n",
    "   X_1^* := \\sum_{j=1}^N W_j x_{j1}\n",
    "\\end{equation*}\n",
    "and the total among the unvaccinated is\n",
    "\\begin{equation*}\n",
    "   X_0^* := \\sum_{j=1}^N (1-W_j) x_{j0}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Under the strong null that the vaccine makes no difference whatsoever--as if whether a subject would become ill was predetermined before assignment to treatment or control--the distribution of the number of infections among the vaccinated would have a hypergeometric distribution with parameters $N$, $G=X_0^*+X_1^*$, and $n=n$.\n",
    "Testing the strong null using this hypergeometric distribution yields _Fisher's Exact Test_.\n",
    "\n",
    "This model can be generalized by considering the total number of infections $X_0^*+X_1^*$ to be random, then conditioning on the observed value to get a conditional test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference about the size of the treatment effect\n",
    "\n",
    "But how can we find a confidence interval for the treatment effect?\n",
    "\n",
    "First, we need to define what we mean by the treatment effect!\n",
    "\n",
    "#### Effect Size for the Weak Null\n",
    "\n",
    "Recall that the \"weak\" null hypothesis that average response is the same, regardless\n",
    "of the assigned treatment (but individuals might have different responses to treatment).\n",
    "Define $\\bar{X}_0 := X_0^*/(N-n)$ and $\\bar{X}_1 := X_1^*/n$, the observed mean\n",
    "responses for the control group and the treatment group.\n",
    "These are unbiased estimates of \n",
    "the corresponding population parameters,\n",
    "\\begin{equation*}\n",
    "\\bar{x}_0 := \\frac{1}{N} \\sum_{j=1}^n x_{j0}\n",
    "\\end{equation*}\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\bar{x}_1 := \\frac{1}{N} \\sum_{j=1}^n x_{j1}.\n",
    "\\end{equation*}\n",
    "\n",
    "The _average treatment effect_ for the study population is\n",
    "\\begin{equation*}\n",
    "\\tau := \\bar{x}_1 - \\bar{x}_0 = \\frac{1}{N} \\sum_{j=1}^N (x_{1j}-x_{0j}) = \\frac{1}{N} \\sum_{j=1}^N \\tau_j,\n",
    "\\end{equation*}\n",
    "where $\\tau_j := x_{1j}-x_{0j}$.\n",
    "An unbiased estimate of $\\tau$ is $\\hat{\\tau} := \\bar{X}_1 - \\bar{X}_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study population can be summarized by 4 numbers, $N_{00}$, $N_{01}$, $N_{10}$, and $N_{11}$, where $N_{ik}$ is the number of subjects $j$ for whom \n",
    "$x_{j0} = k$ and $x_{j1} = k$, for $i, k \\in \\{0, 1\\}$.\n",
    "Of course, $N = N_{00} + N_{01} + N_{10} + N_{11}$.\n",
    "The average treatment effect can be written $\\tau = (N_{01}-N_{10})/N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First approach: Bonferroni simultaneous confidence intervals\n",
    "\n",
    "A collection of confidence set procedures $\\{\\mathcal{I}_i \\}_{i=1}^m$ for a corresponding set of parameters $\\{ \\theta_i \\}_{i=1}^m$ has _simultaneous coverage probability_ $1-\\alpha$ if\n",
    "\\begin{equation*}\n",
    "\\mathbb{P}_{\\theta_1, \\ldots, \\theta_m} \\cap_{i=1}^m ( \\theta_i \\in \\mathcal{I}_i ) \\ge 1-\\alpha\n",
    "\\end{equation*}\n",
    "whatever the true values $\\{\\theta_i\\}$ are.\n",
    "\n",
    "Bonferroni's inequality says that for any collection of events $\\{A_i\\}$,\n",
    "\\begin{equation*}\n",
    "\\mathbb{P} \\left ( \\cup_i A_i \\right ) \\le \\sum_i \\mathbb{P}(A_i).\n",
    "\\end{equation*}.\n",
    "It follows that if $\\mathcal{I}_i$ is a confidence interval procedure for $\\theta_i$ with coverage probability $1-\\alpha_i$, $i=1, \\ldots, m$, then the collection of\n",
    "confidence set procedures $\\{\\mathcal{I}_i \\}_{i=1}^m$ has simultaneous coverage probability\n",
    "not smaller than $1-\\sum_i \\alpha_i$.\n",
    "\n",
    "In the current situation, if we had simultaneous confidence sets for both $N_{01}$ and $N_{10}$, we could find a confidence set for $\\tau$ because $\\tau = (N_{01}-N_{10})/N$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second approach: testing all 2x2 tables of potential outcomes\n",
    "\n",
    "After the randomization, for each subject $j$, we observe either $x_{j0}$ or\n",
    "$x_{j1}$.\n",
    "At that point, we know $N$ of the $2N$ numbers $\\{x_{jk}\\}_{j=1}^N{}_{k=0}^1$.\n",
    "The other $N$ numbers--the responses that were not observed--can be any combination of 0s and 1s: there are $2^N$ possibilities in all.\n",
    "\n",
    "But at the end of the day, all that matters are the four numbers $N_{00}$, $N_{01}$, $N_{10}$, and $N_{11}$.\n",
    "Together, these sum to $N$. \n",
    "The total number of ways there are of partitioning $N$ items into 4 groups can be found by Feller's \"bars and stars\" argument (see the [notes on nuisance parameters](./nuisance.ipynb));\n",
    "the answer is $\\binom{N+3}{3}$. \n",
    "This is $O(N^3)$ tables\n",
    "([Rigdon and Hudgens (2015)](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6384)).\n",
    "But many of those tables are incompatible with the observed data.\n",
    "[Li and Ding (2016)](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6764) show that taking into account the observed data constrains\n",
    "the number of tables to $O(N^2)$, greatly speeding the computation.\n",
    "\n",
    "The (unknown) complete table of results is as follows:\n",
    "\n",
    "$w_j$      | $x_{j0}$   | $x_{j1}$ |\n",
    ":-----:    | :------:   | :------: |\n",
    " 1         |    0       |    0     |\n",
    " 1         |    0       |    0     |\n",
    " 1         |    1       |    0     |\n",
    " 1         |    1       |    1     |\n",
    " 1         |    0       |    1     |\n",
    " $\\cdots$   | $\\cdots$   | $\\cdots$  |\n",
    " 0         |    0       |    0     |\n",
    " 0         |    0       |    1     |\n",
    " 0         |    1       |    1     |\n",
    " $\\cdots$   | $\\cdots$   | $\\cdots$  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[MORE TO COME]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}


<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. Homework 5: Selective inference and outlier rejection &#8212; Collaborative and Reproducible Data Science</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Homework 6: Cryptorandom - contributing to an open source project" href="hw06-cryptorandom-contrib.html" />
    <link rel="prev" title="4. Homework 4: Reproducibility, Philosophy of Science, and COVID-19 Models" href="hw04-phil-sci-covid.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Collaborative and Reproducible Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Statistics 159/259, Spring 2021 Course Summary
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../schedule.html">
   Statistics 159/259: Weekly Plan
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../syllabus.html">
   Syllabus for Statistics 159/259: Reproducible and Collaborative Statistical Data Science
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Homework Assignments
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="hw01-background.html">
   1. Homework 1. Stats review and intro to Git
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hw02-election-fraud.html">
   2. Homework 2. Election Fraud
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hw03-testing.html">
   3. Homework 3: Coding style, docstrings, algorithmic choices, and unit tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hw04-phil-sci-covid.html">
   4. Homework 4: Reproducibility, Philosophy of Science, and COVID-19 Models
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. Homework 5: Selective inference and outlier rejection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hw06-cryptorandom-contrib.html">
   6. Homework 6: Cryptorandom - contributing to an open source project
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Lecture Notes
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Notes/01/index.html">
   Introduction to Git and Github
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Notes/index.html">
   An Idiosyncratic Sample of Applied Statistics
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Lecture Index
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../Index/index.html">
   Index of Lectures and Materials
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Hw/hw05-selection-outliers.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#points-selective-inference">
   5.1. [20 points] Selective inference
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#points-outlier-rejection-and-the-trimmed-mean">
   5.2. [6 points] Outlier rejection and the trimmed mean
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#points-outliers-computational-example">
   5.3. [14 points] Outliers: computational example
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#points-implementation-comparison">
     5.3.1. [6 points] Implementation Comparison
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#points-trimmed-mean">
     5.3.2. [4 points] Trimmed mean
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#points-outlier-rejection">
     5.3.3. [4 points] Outlier rejection
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="homework-5-selective-inference-and-outlier-rejection">
<h1><span class="section-number">5. </span>Homework 5: Selective inference and outlier rejection<a class="headerlink" href="#homework-5-selective-inference-and-outlier-rejection" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><strong>Statistics 159/259, Spring 2021</strong></p></li>
<li><p><strong>Due 3/8/2021, 11:59PM PT</strong></p></li>
<li><p>Profs. Pérez and Stark, Department of Statistics, UC Berkeley.</p></li>
<li><p>This assignment is worth a maximum of <strong>40 points</strong>.</p></li>
<li><p>Assignment type: <strong>individual</strong>.</p></li>
</ul>
<p>This brief assignment (a little computation and a modest amount of thinking) uses simulation to illustrate
the problem of selective inference (selecting what to compute or report based on the the data)
and why blind “rejection” of outliers can be misleading.</p>
<p>Both topics have to do with “researcher degrees of freedom,” i.e., decisions the data analyst
makes that can alter or distort the results and conclusions.
See, e.g., <a class="reference external" href="http://stat.columbia.edu/~gelman/research/published/ForkingPaths.pdf">Gelman, A., and E. Loken, 2014. The Statistical Crisis in Science, <em>American Scientist</em>,
102, 460–465</a>.</p>
<p><strong>Deliverable:</strong> for this assignment, please turn in:</p>
<ul class="simple">
<li><p>One notebook that includes code for plots and simulations, along with your written responses and discussion. Please remember to use markdown headings for each section/subsection so the entire document is readable.</p></li>
<li><p>The notebook should include the capture of the run of your unit tests like you’ve done before (see next point).</p></li>
<li><p>A python file called <code class="docutils literal notranslate"><span class="pre">lognormals.py</span></code> with your three implementations of a lognormal random variable, accompanied by a file called <code class="docutils literal notranslate"><span class="pre">test_lognormals.py</span></code> that includes the unit tests.</p></li>
</ul>
<div class="section" id="points-selective-inference">
<h2><span class="section-number">5.1. </span>[20 points] Selective inference<a class="headerlink" href="#points-selective-inference" title="Permalink to this headline">¶</a></h2>
<p>Imagine that you are selecting variables to include in a regression model.
A common method for selecting which coefficients/variables/parameters to include in a
regression or other statistical model is to keep the variable if the estimated coefficient
<span class="math notranslate nohighlight">\(|\hat{\theta}|\)</span> is “significant,” i.e., if the t-statistic or z-statistic for the estimated
coefficient is large.<br />
Having chosen which variables to keep using a method like that, analysts often then report
confidence intervals for the coefficients, as if they had not already used the data to
decide which variables to keep in the model.
This is called “selective inference,” as described in the citations below.
Selective inference leads to problems with statistical reproducibility for many reasons.
This assignment highlights one of them: confidence intervals can be far less likely to
contain the true value of the parameter when you use the data to select which parameters to
report confidence intervals for.</p>
<p>To keep things simple, we will pretend that the standard error of the coefficient is known
(and is equal to one), rather than estimated, so instead of using Student’s <span class="math notranslate nohighlight">\(t\)</span> distribution
we can use the standard normal distribution.
In this exercise, <span class="math notranslate nohighlight">\(X\)</span> plays the role of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>.
You will simulate <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>; <span class="math notranslate nohighlight">\(X\)</span> is then an unbiased estimate of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>[3 points]</p>
<ul class="simple">
<li><p>For each <span class="math notranslate nohighlight">\(\theta \in \{-3, -2.9, \ldots, -0.1, 0, 0.1, \ldots, 2.9, 3 \}\)</span>, simulate a
draw <span class="math notranslate nohighlight">\(X \sim N(\theta, 1)\)</span>.</p></li>
<li><p>If the draw is “statistically significant at level 0.05,” i.e., if <span class="math notranslate nohighlight">\(|X| \ge 1.96\)</span>,
construct the usual 95% confidence interval for <span class="math notranslate nohighlight">\(\theta\)</span> from the draw, i.e., <span class="math notranslate nohighlight">\([X-1.96, X+1.96]\)</span>.
If <span class="math notranslate nohighlight">\(|X| &lt; 1.96\)</span>, do not make a confidence interval.
For each confidence interval, record whether it contains the value of <span class="math notranslate nohighlight">\(\theta\)</span> used to generate <span class="math notranslate nohighlight">\(X\)</span>.
Repeat until you have constructed 10,000 confidence intervals for each value of <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
</ul>
<p>[3 points]</p>
<ul class="simple">
<li><p>Plot the fraction of the 10,000 confidence intervals for <span class="math notranslate nohighlight">\(\theta\)</span> that contain <span class="math notranslate nohighlight">\(\theta\)</span>,
as a function of <span class="math notranslate nohighlight">\(\theta\)</span>.
(I.e., plot the empirical coverage rate of the confidence intervals.)</p></li>
</ul>
<p>[3 points]</p>
<ul class="simple">
<li><p>Include unit tests for every function.</p></li>
</ul>
<p>[3 points]</p>
<ul class="simple">
<li><p>Explain why the plot looks the way it does.</p></li>
</ul>
<p>[8 points]</p>
<ul class="simple">
<li><p>Suppose you wanted to create a procedure that had at least 95% coverage probability, no
matter what <span class="math notranslate nohighlight">\(\theta\)</span> is.</p>
<ul>
<li><p>Sketch how you would have to modify the usual normal confidence interval.
(I don’t expect you to work out the math, just explain heuristically how the confidence interval
would have to behave.)</p></li>
<li><p>Would the interval be symmetric around <span class="math notranslate nohighlight">\(X\)</span>?</p></li>
<li><p>Would it be longer or shorter than the standard interval?</p></li>
<li><p>What other differences would you expect?</p></li>
</ul>
</li>
</ul>
<p><em>Hint:</em> consider asymmetric confidence intervals.</p>
<p><em>Extra hint:</em> see</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1198/016214504000001907">Benjamini, Y. and D. Yekutieli, 2005.
False Discovery Rate-Adjusted Multiple Confidence Intervals for Selected Parameters,
<em>Journal of the American Statistical Association, Theory
and Methods</em>, <em>100</em>(469), DOI 10.1198/016214504000001907</a></p></li>
<li><p>The <a class="reference external" href="https://www.selectiveinferenceseminar.com">online Seminar on Selective Inference</a> is a great resource on this topic. In particular you may want to watch the talk on “Confidence Intervals for Selected Parameters” by Benjamini - <a class="reference external" href="https://drive.google.com/file/d/1D2cq1n_e0LlbxvQjyG0feNKPd4GY1ZCe/view?usp=sharing">recording</a>, <a class="reference external" href="https://drive.google.com/file/d/1qGk4wFZkBEizYEUyGL7HCaduV_GXNMvj/view">slides</a> and <a class="reference external" href="https://arxiv.org/abs/1906.00505">preprint co-authored with Hechtlinger &amp; Stark</a>.</p></li>
</ul>
</div>
<div class="section" id="points-outlier-rejection-and-the-trimmed-mean">
<h2><span class="section-number">5.2. </span>[6 points] Outlier rejection and the trimmed mean<a class="headerlink" href="#points-outlier-rejection-and-the-trimmed-mean" title="Permalink to this headline">¶</a></h2>
<p>It is common to discard extreme data as “outliers.”
Two common ways of dealing with putative outliers are to discard observations that are
more than some number of sample standard deviations from the sample mean (“outlier rejection”) and to discard
some fraction of the most extreme observations (the “trimmed mean” and related statistics).
This exercise explores the effect discarding extreme observations
can have on the bias, accuracy, and reliability of estimates.</p>
<p><a class="reference external" href="https://www.scienceopen.com/document?vid=b1353421-2e05-4a79-9c6f-4ac5a44dcc03">Uttl and Violo (2020)</a>
claim that the conclusions of MacNell et al. (2015) are incorrect because MacNell et al. include
three outliers.</p>
<p>[1 point]</p>
<ul class="simple">
<li><p>What are Uttl and Viola’s arguments to justify discarding data?</p></li>
</ul>
<p>[1 point]</p>
<ul class="simple">
<li><p>What are the assumptions of their arguments?</p></li>
</ul>
<p>[2 points]</p>
<ul class="simple">
<li><p>Sketch a real-world scenario where you think it is scientifically justified to discard “outliers,”
and explain why it is justified.</p></li>
</ul>
<p>[2 points]</p>
<ul class="simple">
<li><p>Sketch a real-world scenario where you think it is not scientifically justified to discard “outliers,”
and explain why.</p></li>
</ul>
</div>
<div class="section" id="points-outliers-computational-example">
<h2><span class="section-number">5.3. </span>[14 points] Outliers: computational example<a class="headerlink" href="#points-outliers-computational-example" title="Permalink to this headline">¶</a></h2>
<p>This example involves simulating from a lognormal distribution. It shows that discarding extreme
observations can produce misleading results, both for point estimates and confidence intervals.</p>
<div class="section" id="points-implementation-comparison">
<h3><span class="section-number">5.3.1. </span>[6 points] Implementation Comparison<a class="headerlink" href="#points-implementation-comparison" title="Permalink to this headline">¶</a></h3>
<p>Implement three separate ways of simulating a lognormal random variable:</p>
<ul class="simple">
<li><p>use <code class="docutils literal notranslate"><span class="pre">scipy.stats.lognorm</span></code></p></li>
<li><p>use <code class="docutils literal notranslate"><span class="pre">scipy.stats.norm</span></code> and exponentiate</p></li>
<li><p>use <code class="docutils literal notranslate"><span class="pre">scipy.stats.uniform</span></code> and the inverse probability transformation (you can use the scipy implementation of the normal CDF and inverse normal CDF as part of your solution)</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>the calling signatures and return signatures of the three functions should be the same</p></li>
<li><p>provide comparisons and appropriate unit tests for the latter two approaches. Run a timing comparison (remember the <code class="docutils literal notranslate"><span class="pre">%timeit</span></code> magic), and think of how you can validate that all implementations are ultimately giving the same answer.</p></li>
<li><p>explain why the inverse probability transform method for simulating random variables involves the assumption that the distribution is continuous.</p>
<ul>
<li><p>What goes wrong (or has to be changed) if the distribution is discrete?</p></li>
<li><p>If you can, provide a more general approach that also works for discrete random variables and for random
variables that are “mixed” (neither continuous nor discrete)</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>What is the expected value of a lognormal distribution with parameters <span class="math notranslate nohighlight">\(\mu=0\)</span>, <span class="math notranslate nohighlight">\(\sigma=1\)</span>?</p></li>
</ul>
</div>
<div class="section" id="points-trimmed-mean">
<h3><span class="section-number">5.3.2. </span>[4 points] Trimmed mean<a class="headerlink" href="#points-trimmed-mean" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Repeat 10,000 times:</p>
<ul>
<li><p>simulate 40 draws from a standard lognormal distribution</p></li>
<li><p>calculate the 5% trimmed mean (i.e., discard the 5% smallest and 5% largest observations–two points
from each end–and take the mean of the remaining 36 points)</p></li>
<li><p>calculate a “formal” normal 95% confidence interval based on the 36 remaining points, that is,
the trimmed mean plus and minus 1.96 times the sample standard deviation of the 36 points, divided by 6,
(the square root of 36).</p></li>
</ul>
</li>
<li><p>compare the mean of the 10,000 trimmed means to the true expected value of the lognormal distribution, and report the
percentage of the 10,000 intervals that contain the true expected value.</p>
<ul>
<li><p>Explain why the mean of the sample means differs from the expected value of the lognormal in the direction it does.</p></li>
<li><p>Explain why the percentage of intervals that cover the true expected value differs from 95% in the direction it does.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="points-outlier-rejection">
<h3><span class="section-number">5.3.3. </span>[4 points] Outlier rejection<a class="headerlink" href="#points-outlier-rejection" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Repeat 10,000 times:</p>
<ul>
<li><p>simulate 40 draws from a standard lognormal distribution</p></li>
<li><p>discard any observations that are more than 2 sample standard deviations from the sample
mean. Take the mean of the remaining points.</p></li>
<li><p>calculate a “formal” normal 95% confidence interval based on the remaining points, that is,
the mean plus and minus 1.96 times the sample standard deviation of the remaining points, divided by the square
root of the number of remaining points.</p></li>
</ul>
</li>
<li><p>compare the mean of the 10,000 “outlier-rejection” means to the true expected value of the lognormal distribution, and report the
percentage of the 10,000 intervals that contain the true expected value.</p>
<ul>
<li><p>Explain why the mean of the sample means differs from the expected value of the lognormal in the direction it does.</p></li>
<li><p>Explain why the percentage of intervals that cover the true expected value differs from 95% in the direction it does.</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Hw"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="hw04-phil-sci-covid.html" title="previous page"><span class="section-number">4. </span>Homework 4: Reproducibility, Philosophy of Science, and COVID-19 Models</a>
    <a class='right-next' id="next-link" href="hw06-cryptorandom-contrib.html" title="next page"><span class="section-number">6. </span>Homework 6: Cryptorandom - contributing to an open source project</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Philip Stark and Fernando Pérez<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>